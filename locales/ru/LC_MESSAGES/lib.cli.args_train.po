# SOME DESCRIPTIVE TITLE.
# Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-03-28 18:04+0000\n"
"PO-Revision-Date: 2024-03-28 18:18+0000\n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: ru\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<12 || n%100>14) ? 1 : 2);\n"
"X-Generator: Poedit 3.4.2\n"

#: lib/cli/args_train.py:30
msgid ""
"Train a model on extracted original (A) and swap (B) faces.\n"
"Training models can take a long time. Anything from 24hrs to over a week\n"
"Model plugins can be configured in the 'Settings' Menu"
msgstr ""
"Обучение модели на извлеченных оригинальных (A) и подмененных (B) лицах.\n"
"Обучение моделей может занять много времени. От 24 часов до недели.\n"
"Плагины для моделей можно настроить в меню \"Настройки\""

#: lib/cli/args_train.py:49 lib/cli/args_train.py:58
msgid "faces"
msgstr "лица"

#: lib/cli/args_train.py:51
msgid ""
"Input directory. A directory containing training images for face A. This is "
"the original face, i.e. the face that you want to remove and replace with "
"face B."
msgstr ""
"Входная папка. Папка, содержащая обучающие изображения для лица A. Это "
"исходное лицо, т.е. лицо, которое вы хотите удалить и заменить лицом B."

#: lib/cli/args_train.py:60
msgid ""
"Input directory. A directory containing training images for face B. This is "
"the swap face, i.e. the face that you want to place onto the head of person "
"A."
msgstr ""
"Входная папка. Папка, содержащая обучающие изображения для лица B. Это "
"подменное лицо, т.е. лицо, которое вы хотите поместить на голову человека A."

#: lib/cli/args_train.py:67 lib/cli/args_train.py:80 lib/cli/args_train.py:97
#: lib/cli/args_train.py:123 lib/cli/args_train.py:133
msgid "model"
msgstr "модель"

#: lib/cli/args_train.py:69
msgid ""
"Model directory. This is where the training data will be stored. You should "
"always specify a new folder for new models. If starting a new model, select "
"either an empty folder, or a folder which does not exist (which will be "
"created). If continuing to train an existing model, specify the location of "
"the existing model."
msgstr ""
"Папка модели. Здесь будут храниться данные для обучения. Для новых моделей "
"всегда следует указывать новую папку. Если вы начинаете новую модель, "
"выберите либо пустую папку, либо несуществующую папку (которая будет "
"создана). Если вы продолжаете обучение существующей модели, укажите "
"местоположение существующей модели."

#: lib/cli/args_train.py:82
msgid ""
"R|Load the weights from a pre-existing model into a newly created model. For "
"most models this will load weights from the Encoder of the given model into "
"the encoder of the newly created model. Some plugins may have specific "
"configuration options allowing you to load weights from other layers. "
"Weights will only be loaded when creating a new model. This option will be "
"ignored if you are resuming an existing model. Generally you will also want "
"to 'freeze-weights' whilst the rest of your model catches up with your "
"Encoder.\n"
"NB: Weights can only be loaded from models of the same plugin as you intend "
"to train."
msgstr ""
"R|Загрузить веса из уже существующей модели во вновь созданную модель. Для "
"большинства моделей это означает загрузку весов из кодировщика данной модели "
"в кодировщик вновь создаваемой модели. Некоторые плагины могут иметь "
"специальные параметры конфигурации, позволяющие загружать веса из других "
"слоев. Веса будут загружаться только при создании новой модели. Эта опция "
"будет проигнорирована, если вы возобновляете существующую модель. Обычно "
"также требуется \"заморозить\" веса, пока остальная часть модели догоняет "
"кодировщик.\n"
"Примечание: Веса могут быть загружены только из моделей того же плагина, "
"который вы собираетесь обучать."

#: lib/cli/args_train.py:99
msgid ""
"R|Select which trainer to use. Trainers can be configured from the Settings "
"menu or the config folder.\n"
"L|original: The original model created by /u/deepfakes.\n"
"L|dfaker: 64px in/128px out model from dfaker. Enable 'warp-to-landmarks' "
"for full dfaker method.\n"
"L|dfl-h128: 128px in/out model from deepfacelab\n"
"L|dfl-sae: Adaptable model from deepfacelab\n"
"L|dlight: A lightweight, high resolution DFaker variant.\n"
"L|iae: A model that uses intermediate layers to try to get better details\n"
"L|lightweight: A lightweight model for low-end cards. Don't expect great "
"results. Can train as low as 1.6GB with batch size 8.\n"
"L|realface: A high detail, dual density model based on DFaker, with "
"customizable in/out resolution. The autoencoders are unbalanced so B>A swaps "
"won't work so well. By andenixa et al. Very configurable.\n"
"L|unbalanced: 128px in/out model from andenixa. The autoencoders are "
"unbalanced so B>A swaps won't work so well. Very configurable.\n"
"L|villain: 128px in/out model from villainguy. Very resource hungry (You "
"will require a GPU with a fair amount of VRAM). Good for details, but more "
"susceptible to color differences."
msgstr ""
"R|Выберите, какой тренажер использовать. Тренажеры можно настроить в меню "
"\"Настройки\" или в папке config.\n"
"L|original: Оригинальная модель, созданная /u/deepfakes.\n"
"L|dfaker: модель 64px вход/ 128px выход от dfaker. Включите 'warp-to-"
"landmarks' для полного метода dfaker.\n"
"L|dfl-h128: модель 128px вход/выход от deepfacelab\n"
"L|dfl-sae: Адаптируемая модель от deepfacelab\n"
"L|dlight: Легкий вариант DFaker с высоким разрешением.\n"
"L|iae: Модель, использующая промежуточные слои для получения лучших "
"деталей.\n"
"L|lightweight: Облегченная модель для карт низкого класса. Не ожидайте "
"высоких результатов. Может обучаться на 1,6 ГБ при размере пачки 8.\n"
"L|realface: Модель с высокой детализацией и двойной плотностью, основанная "
"на DFaker, с настраиваемым разрешением входа/выхода. Автоэнкодеры "
"несбалансированы, поэтому замены B>A не будут работать так хорошо. Автор "
"andenixa и др. Очень настраиваемая.\n"
"L|unbalanced: модель 128px вход/выход от andenixa. Автокодировщики "
"несбалансированы, поэтому замены B>A не будут работать так хорошо. Очень "
"настраиваемая.\n"
"L|villain: модель 128px вход/выход от villainguy. Очень требовательна к "
"ресурсам (вам потребуется GPU с достаточным количеством VRAM). Хороша для "
"детализации, но более восприимчива к цветовым различиям."

#: lib/cli/args_train.py:125
msgid ""
"Output a summary of the model and exit. If a model folder is provided then a "
"summary of the saved model is displayed. Otherwise a summary of the model "
"that would be created by the chosen plugin and configuration settings is "
"displayed."
msgstr ""
"Вывести сводку модели и выйти. Если указана папка модели, то выводится "
"сводка сохраненной модели. В противном случае отображается сводка модели, "
"которая будет создана выбранным плагином и настройками конфигурации."

#: lib/cli/args_train.py:135
msgid ""
"Freeze the weights of the model. Freezing weights means that some of the "
"parameters in the model will no longer continue to learn, but those that are "
"not frozen will continue to learn. For most models, this will freeze the "
"encoder, but some models may have configuration options for freezing other "
"layers."
msgstr ""
"Заморозить веса модели. Замораживание весов означает, что некоторые "
"параметры в модели больше не будут продолжать обучение, но те, которые не "
"заморожены, будут продолжать обучение. Для большинства моделей это означает "
"замораживание кодера, но некоторые модели могут иметь опции конфигурации для "
"замораживания других слоев."

#: lib/cli/args_train.py:147 lib/cli/args_train.py:160
#: lib/cli/args_train.py:175 lib/cli/args_train.py:191
#: lib/cli/args_train.py:200
msgid "training"
msgstr "тренировка"

#: lib/cli/args_train.py:149
msgid ""
"Batch size. This is the number of images processed through the model for "
"each side per iteration. NB: As the model is fed 2 sides at a time, the "
"actual number of images within the model at any one time is double the "
"number that you set here. Larger batches require more GPU RAM."
msgstr ""
"Размер пачки. Это количество изображений, обрабатываемых моделью для каждой "
"стороны за итерацию. Примечание: Поскольку модель обрабатывает 2 стороны "
"одновременно, фактическое количество изображений в модели в любой момент "
"времени будет вдвое больше, чем заданное здесь. Большие партии требуют "
"больше оперативной памяти GPU."

#: lib/cli/args_train.py:162
msgid ""
"Length of training in iterations. This is only really used for automation. "
"There is no 'correct' number of iterations a model should be trained for. "
"You should stop training when you are happy with the previews. However, if "
"you want the model to stop automatically at a set number of iterations, you "
"can set that value here."
msgstr ""
"Продолжительность обучения в итерациях. Этот параметр действительно "
"используется только для автоматизации. Не существует \"правильного\" "
"количества итераций, за которое следует обучить модель. Вы должны прекратить "
"обучение, когда будете удовлетворены предварительным просмотром. Однако если "
"вы хотите, чтобы модель автоматически останавливалась при определенном "
"количестве итераций, вы можете задать это значение здесь."

#: lib/cli/args_train.py:177
msgid ""
"R|Select the distribution stategy to use.\n"
"L|default: Use Tensorflow's default distribution strategy.\n"
"L|central-storage: Centralizes variables on the CPU whilst operations are "
"performed on 1 or more local GPUs. This can help save some VRAM at the cost "
"of some speed by not storing variables on the GPU. Note: Mixed-Precision is "
"not supported on multi-GPU setups.\n"
"L|mirrored: Supports synchronous distributed training across multiple local "
"GPUs. A copy of the model and all variables are loaded onto each GPU with "
"batches distributed to each GPU at each iteration."
msgstr ""
"R|Выберите стратегию распределения для использования.\n"
"L|default: Использовать стратегию распространения Tensorflow по умолчанию.\n"
"L|central-storage: Централизует переменные на CPU, в то время как операции "
"выполняются на 1 или более локальных GPU. Это может помочь сэкономить "
"немного VRAM за счет некоторой скорости, поскольку переменные не хранятся на "
"GPU. Примечание: Mixed-Precision не поддерживается на многопроцессорных "
"установках.\n"
"L|mirrored: Поддерживает синхронное распределенное обучение на нескольких "
"локальных GPU. Копия модели и все переменные загружаются на каждый GPU с "
"распределением партий на каждый GPU на каждой итерации."

#: lib/cli/args_train.py:193
msgid ""
"Disables TensorBoard logging. NB: Disabling logs means that you will not be "
"able to use the graph or analysis for this session in the GUI."
msgstr ""
"Отключает ведение журналов TensorBoard. Примечание: Отключение ведения "
"журналов означает, что вы не сможете использовать график или анализ для этой "
"сессии в графическом интерфейсе."

#: lib/cli/args_train.py:202
msgid ""
"Use the Learning Rate Finder to discover the optimal learning rate for "
"training. For new models, this will calculate the optimal learning rate for "
"the model. For existing models this will use the optimal learning rate that "
"was discovered when initializing the model. Setting this option will ignore "
"the manually configured learning rate (configurable in train settings)."
msgstr ""
"Используйте инструмент поиска коэффициента обучения, чтобы найти оптимальную "
"скорость обучения вашей модели. Для новых моделей это позволит рассчитать "
"оптимальный коэффициент обучения для модели. Для существующих моделей будет "
"использован оптимальный коэффициент обучения, найденный при инициализации "
"модели. Установка этой опции приведет к игнорированию вручную настроенного "
"коэффициента обучения (настраиваемого в параметрах обучения)."

#: lib/cli/args_train.py:215 lib/cli/args_train.py:225
msgid "Saving"
msgstr "Сохранение"

#: lib/cli/args_train.py:216
msgid "Sets the number of iterations between each model save."
msgstr "Устанавливает количество итераций между каждым сохранением модели."

#: lib/cli/args_train.py:227
msgid ""
"Sets the number of iterations before saving a backup snapshot of the model "
"in it's current state. Set to 0 for off."
msgstr ""
"Устанавливает количество итераций между каждым сохранением модели. "
"Устанавливает количество итераций перед сохранением резервного снимка модели "
"в текущем состоянии. Установите значение 0 для выключения."

#: lib/cli/args_train.py:234 lib/cli/args_train.py:246
#: lib/cli/args_train.py:258
msgid "timelapse"
msgstr "таймлапс"

#: lib/cli/args_train.py:236
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. "
"This should be the input folder of 'A' faces that you would like to use for "
"creating the timelapse. You must also supply a --timelapse-output and a --"
"timelapse-input-B parameter."
msgstr ""
"Опционально для создания таймлапса. Timelapse будет сохранять изображение "
"выбранных лиц в папку timelapse-output на каждой итерации сохранения. Это "
"должна быть входная папка с лицами 'A', которые вы хотите использовать для "
"создания timelapse. Вы также должны указать параметры --timelapse-output и --"
"timelapse-input-B."

#: lib/cli/args_train.py:248
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. "
"This should be the input folder of 'B' faces that you would like to use for "
"creating the timelapse. You must also supply a --timelapse-output and a --"
"timelapse-input-A parameter."
msgstr ""
"Опционально для создания таймлапса. Timelapse будет сохранять изображение "
"выбранных лиц в папку timelapse-output на каждой итерации сохранения. Это "
"должна быть входная папка с лицами 'B', которые вы хотите использовать для "
"создания timelapse. Вы также должны указать параметры --timelapse-output и --"
"timelapse-input-A."

#: lib/cli/args_train.py:260
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. If "
"the input folders are supplied but no output folder, it will default to your "
"model folder/timelapse/"
msgstr ""
"Опционально для создания таймлапса. Timelapse будет сохранять изображение "
"выбранных лиц в папку timelapse-output на каждой итерации сохранения. Если "
"указаны входные папки, но нет выходной папки, то по умолчанию будет выбрана "
"папка модели/timelapse/"

#: lib/cli/args_train.py:269 lib/cli/args_train.py:276
msgid "preview"
msgstr "предпросмотр"

#: lib/cli/args_train.py:270
msgid "Show training preview output. in a separate window."
msgstr "Показать вывод предварительного просмотра тренировки в отдельном окне."

#: lib/cli/args_train.py:278
msgid ""
"Writes the training result to a file. The image will be stored in the root "
"of your FaceSwap folder."
msgstr ""
"Записывает результат обучения в файл. Изображение будет сохранено в корне "
"папки Faceswap."

#: lib/cli/args_train.py:285 lib/cli/args_train.py:295
#: lib/cli/args_train.py:305 lib/cli/args_train.py:315
msgid "augmentation"
msgstr "аугментация"

#: lib/cli/args_train.py:287
msgid ""
"Warps training faces to closely matched Landmarks from the opposite face-set "
"rather than randomly warping the face. This is the 'dfaker' way of doing "
"warping."
msgstr ""
"Искажает обучаемые лица до близко подходящих ориентиров из противоположного "
"набора лиц вместо случайного искажения лица. Это способ выполнения искажения "
"от \"dfaker\" ."

#: lib/cli/args_train.py:297
msgid ""
"To effectively learn, a random set of images are flipped horizontally. "
"Sometimes it is desirable for this not to occur. Generally this should be "
"left off except for during 'fit training'."
msgstr ""
"Для эффективного обучения случайный набор изображений переворачивается по "
"горизонтали. Иногда желательно, чтобы этого не происходило. Как правило, это "
"не нужно делать, за исключением случаев \"тренировки подгонки\"."

#: lib/cli/args_train.py:307
msgid ""
"Color augmentation helps make the model less susceptible to color "
"differences between the A and B sets, at an increased training time cost. "
"Enable this option to disable color augmentation."
msgstr ""
"Аугментация цвета помогает сделать модель менее восприимчивой к цветовым "
"различиям между наборами A и B, что влечет за собой увеличение затрат "
"времени на обучение. Включите этот параметр для отключения цветовой "
"аугментации."

#: lib/cli/args_train.py:317
msgid ""
"Warping is integral to training the Neural Network. This option should only "
"be enabled towards the very end of training to try to bring out more detail. "
"Think of it as 'fine-tuning'. Enabling this option from the beginning is "
"likely to kill a model and lead to terrible results."
msgstr ""
"Искажение является неотъемлемой частью обучения нейронной сети. Эту опцию "
"следует включать только в самом конце обучения, чтобы попытаться получить "
"больше деталей. Считайте это \"тонкой настройкой\". Включение этой опции в "
"самом начале, скорее всего, погубит модель и приведет к ужасным результатам."

#~ msgid "Global Options"
#~ msgstr "Глобальные Настройки"

#~ msgid ""
#~ "R|Exclude GPUs from use by Faceswap. Select the number(s) which "
#~ "correspond to any GPU(s) that you do not wish to be made available to "
#~ "Faceswap. Selecting all GPUs here will force Faceswap into CPU mode.\n"
#~ "L|{}"
#~ msgstr ""
#~ "R|Исключить GPU из использования Faceswap. Выберите номер (номера), "
#~ "соответствующие любому GPU, который вы не хотите предоставлять Faceswap. "
#~ "Если выбрать здесь все GPU, Faceswap перейдет в режим CPU.\n"
#~ "L|{}"

#~ msgid ""
#~ "Optionally overide the saved config with the path to a custom config file."
#~ msgstr ""
#~ "Опционально переопределите сохраненную конфигурацию, указав путь к "
#~ "пользовательскому файлу конфигурации."

#~ msgid ""
#~ "Log level. Stick with INFO or VERBOSE unless you need to file an error "
#~ "report. Be careful with TRACE as it will generate a lot of data"
#~ msgstr ""
#~ "Уровень логирования. Придерживайтесь INFO или VERBOSE, если только вам не "
#~ "нужно отправить отчет об ошибке. Будьте осторожны с TRACE, поскольку он "
#~ "генерирует много данных"

#~ msgid ""
#~ "Path to store the logfile. Leave blank to store in the faceswap folder"
#~ msgstr ""
#~ "Путь для хранения файла журнала. Оставьте пустым, чтобы хранить в папке "
#~ "faceswap"

#~ msgid "Data"
#~ msgstr "Данные"

#~ msgid ""
#~ "Input directory or video. Either a directory containing the image files "
#~ "you wish to process or path to a video file. NB: This should be the "
#~ "source video/frames NOT the source faces."
#~ msgstr ""
#~ "Входная папка или видео. Либо каталог, содержащий файлы изображений, "
#~ "которые вы хотите обработать, либо путь к видеофайлу. ПРИМЕЧАНИЕ: Это "
#~ "должно быть исходное видео/кадры, а не исходные лица."

#~ msgid "Output directory. This is where the converted files will be saved."
#~ msgstr "Выходная папка. Здесь будут сохранены преобразованные файлы."

#~ msgid ""
#~ "Optional path to an alignments file. Leave blank if the alignments file "
#~ "is at the default location."
#~ msgstr ""
#~ "Необязательный путь к файлу выравниваний. Оставьте пустым, если файл "
#~ "выравнивания находится в месте по умолчанию."

#~ msgid ""
#~ "Extract faces from image or video sources.\n"
#~ "Extraction plugins can be configured in the 'Settings' Menu"
#~ msgstr ""
#~ "Извлечение лиц из источников изображений или видео.\n"
#~ "Плагины извлечения можно настроить в меню \"Настройки\""

#~ msgid ""
#~ "R|If selected then the input_dir should be a parent folder containing "
#~ "multiple videos and/or folders of images you wish to extract from. The "
#~ "faces will be output to separate sub-folders in the output_dir."
#~ msgstr ""
#~ "R|Если выбрано, то input_dir должен быть родительской папкой, содержащей "
#~ "несколько видео и/или папок с изображениями, из которых вы хотите извлечь "
#~ "изображение. Лица будут выведены в отдельные вложенные папки в output_dir."

#~ msgid "Plugins"
#~ msgstr "Плагины"

#~ msgid ""
#~ "R|Detector to use. Some of these have configurable settings in '/config/"
#~ "extract.ini' or 'Settings > Configure Extract 'Plugins':\n"
#~ "L|cv2-dnn: A CPU only extractor which is the least reliable and least "
#~ "resource intensive. Use this if not using a GPU and time is important.\n"
#~ "L|mtcnn: Good detector. Fast on CPU, faster on GPU. Uses fewer resources "
#~ "than other GPU detectors but can often return more false positives.\n"
#~ "L|s3fd: Best detector. Slow on CPU, faster on GPU. Can detect more faces "
#~ "and fewer false positives than other GPU detectors, but is a lot more "
#~ "resource intensive."
#~ msgstr ""
#~ "R|Детектор для использования. Некоторые из них имеют настраиваемые "
#~ "параметры в '/config/extract.ini' или 'Settings > Configure Extract "
#~ "'Plugins':\n"
#~ "L|cv2-dnn: Экстрактор только для процессора, который является наименее "
#~ "надежным и наименее ресурсоемким. Используйте его, если не используется "
#~ "GPU и важно время.\n"
#~ "L|mtcnn: Хороший детектор. Быстрый на CPU, еще быстрее на GPU. Использует "
#~ "меньше ресурсов, чем другие детекторы на GPU, но часто может давать "
#~ "больше ложных срабатываний.\n"
#~ "L|s3fd: Лучший детектор. Медленный на CPU, более быстрый на GPU. Может "
#~ "обнаружить больше лиц и меньше ложных срабатываний, чем другие детекторы "
#~ "на GPU, но требует гораздо больше ресурсов."

#~ msgid ""
#~ "R|Aligner to use.\n"
#~ "L|cv2-dnn: A CPU only landmark detector. Faster, less resource intensive, "
#~ "but less accurate. Only use this if not using a GPU and time is "
#~ "important.\n"
#~ "L|fan: Best aligner. Fast on GPU, slow on CPU."
#~ msgstr ""
#~ "R|Выравниватель для использования.\n"
#~ "L|cv2-dnn: Детектор ориентиров только для процессора. Быстрее, менее "
#~ "ресурсоемкий, но менее точный. Используйте его, только если не "
#~ "используется GPU и важно время.\n"
#~ "L|fan: Лучший выравниватель. Быстрый на GPU, медленный на CPU."

#~ msgid ""
#~ "R|Additional Masker(s) to use. The masks generated here will all take up "
#~ "GPU RAM. You can select none, one or multiple masks, but the extraction "
#~ "may take longer the more you select. NB: The Extended and Components "
#~ "(landmark based) masks are automatically generated on extraction.\n"
#~ "L|bisenet-fp: Relatively lightweight NN based mask that provides more "
#~ "refined control over the area to be masked including full head masking "
#~ "(configurable in mask settings).\n"
#~ "L|custom: A dummy mask that fills the mask area with all 1s or 0s "
#~ "(configurable in settings). This is only required if you intend to "
#~ "manually edit the custom masks yourself in the manual tool. This mask "
#~ "does not use the GPU so will not use any additional VRAM.\n"
#~ "L|vgg-clear: Mask designed to provide smart segmentation of mostly "
#~ "frontal faces clear of obstructions. Profile faces and obstructions may "
#~ "result in sub-par performance.\n"
#~ "L|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
#~ "frontal faces. The mask model has been specifically trained to recognize "
#~ "some facial obstructions (hands and eyeglasses). Profile faces may result "
#~ "in sub-par performance.\n"
#~ "L|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
#~ "faces. The mask model has been trained by community members and will need "
#~ "testing for further description. Profile faces may result in sub-par "
#~ "performance.\n"
#~ "The auto generated masks are as follows:\n"
#~ "L|components: Mask designed to provide facial segmentation based on the "
#~ "positioning of landmark locations. A convex hull is constructed around "
#~ "the exterior of the landmarks to create a mask.\n"
#~ "L|extended: Mask designed to provide facial segmentation based on the "
#~ "positioning of landmark locations. A convex hull is constructed around "
#~ "the exterior of the landmarks and the mask is extended upwards onto the "
#~ "forehead.\n"
#~ "(eg: `-M unet-dfl vgg-clear`, `--masker vgg-obstructed`)"
#~ msgstr ""
#~ "R|Дополнительный маскер(ы) для использования. Все маски, созданные здесь, "
#~ "будут занимать видеопамять GPU. Вы можете выбрать ни одной, одну или "
#~ "несколько масок, но извлечение может занять больше времени, чем больше "
#~ "масок вы выберете. Примечание: Расширенные маски и маски компонентов (на "
#~ "основе ориентиров) генерируются автоматически при извлечении.\n"
#~ "L|bisenet-fp: Относительно легкая маска на основе NN, которая "
#~ "обеспечивает более точный контроль над маскируемой областью, включая "
#~ "полное маскирование головы (настраивается в настройках маски).\n"
#~ "L|custom: Фиктивная маска, которая заполняет область маски всеми 1 или 0 "
#~ "(настраивается в настройках). Она необходима только в том случае, если вы "
#~ "собираетесь вручную редактировать пользовательские маски в ручном "
#~ "инструменте. Эта маска не задействует GPU, поэтому не будет использовать "
#~ "дополнительную память VRAM.\n"
#~ "L|vgg-clear: Маска предназначена для интеллектуальной сегментации "
#~ "преимущественно фронтальных лиц без препятствий. Профильные лица и "
#~ "препятствия могут привести к снижению производительности.\n"
#~ "L|vgg-obstructed: Маска, разработанная для интеллектуальной сегментации "
#~ "преимущественно фронтальных лиц. Модель маски была специально обучена "
#~ "распознавать некоторые препятствия на лице (руки и очки). Лица в профиль "
#~ "могут иметь низкую производительность.\n"
#~ "L|unet-dfl: Маска, разработанная для интеллектуальной сегментации "
#~ "преимущественно фронтальных лиц. Модель маски была обучена членами "
#~ "сообщества и для дальнейшего описания нуждается в тестировании. "
#~ "Профильные лица могут привести к низкой производительности.\n"
#~ "Автоматически сгенерированные маски выглядят следующим образом:\n"
#~ "L|components: Маска, разработанная для сегментации лица на основе "
#~ "расположения ориентиров. Для создания маски вокруг внешних ориентиров "
#~ "строится выпуклая оболочка.\n"
#~ "L|extended: Маска, предназначенная для сегментации лица на основе "
#~ "расположения ориентиров. Выпуклый корпус строится вокруг внешних "
#~ "ориентиров, и маска расширяется вверх на лоб.\n"
#~ "(например: `-M unet-dfl vgg-clear`, `--masker vgg-obstructed`)"

#~ msgid ""
#~ "R|Performing normalization can help the aligner better align faces with "
#~ "difficult lighting conditions at an extraction speed cost. Different "
#~ "methods will yield different results on different sets. NB: This does not "
#~ "impact the output face, just the input to the aligner.\n"
#~ "L|none: Don't perform normalization on the face.\n"
#~ "L|clahe: Perform Contrast Limited Adaptive Histogram Equalization on the "
#~ "face.\n"
#~ "L|hist: Equalize the histograms on the RGB channels.\n"
#~ "L|mean: Normalize the face colors to the mean."
#~ msgstr ""
#~ "R|Проведение нормализации может помочь выравнивателю лучше выравнивать "
#~ "лица со сложными условиями освещения при затратах на скорость извлечения. "
#~ "Различные методы дают разные результаты на разных наборах. NB: Это не "
#~ "влияет на выходное лицо, только на вход выравнивателя.\n"
#~ "L|none: Не выполнять нормализацию лица.\n"
#~ "L|clahe: Выполнить для лица адаптивную гистограммную эквализацию с "
#~ "ограничением контраста.\n"
#~ "L|hist: Уравнять гистограммы в каналах RGB.\n"
#~ "L|mean: Нормализовать цвета лица к среднему значению."

#~ msgid ""
#~ "The number of times to re-feed the detected face into the aligner. Each "
#~ "time the face is re-fed into the aligner the bounding box is adjusted by "
#~ "a small amount. The final landmarks are then averaged from each "
#~ "iteration. Helps to remove 'micro-jitter' but at the cost of slower "
#~ "extraction speed. The more times the face is re-fed into the aligner, the "
#~ "less micro-jitter should occur but the longer extraction will take."
#~ msgstr ""
#~ "Количество повторных подач обнаруженной области лица в выравниватель. При "
#~ "каждой повторной подаче лица в выравниватель ограничивающая рамка "
#~ "корректируется на небольшую величину. Затем конечные ориентиры "
#~ "усредняются по результатам каждой итерации. Это помогает устранить "
#~ "\"микро-дрожание\", но ценой снижения скорости извлечения. Чем больше раз "
#~ "лицо повторно подается в выравниватель, тем меньше микро-дрожание, но тем "
#~ "больше времени займет извлечение."

#~ msgid ""
#~ "Re-feed the initially found aligned face through the aligner. Can help "
#~ "produce better alignments for faces that are rotated beyond 45 degrees in "
#~ "the frame or are at extreme angles. Slows down extraction."
#~ msgstr ""
#~ "Повторная подача первоначально найденной выровненной области лица через "
#~ "выравниватель. Может помочь получить лучшее выравнивание для лиц, "
#~ "повернутых в кадре более чем на 45 градусов или расположенных под "
#~ "экстремальными углами. Замедляет извлечение."

#~ msgid ""
#~ "If a face isn't found, rotate the images to try to find a face. Can find "
#~ "more faces at the cost of extraction speed. Pass in a single number to "
#~ "use increments of that size up to 360, or pass in a list of numbers to "
#~ "enumerate exactly what angles to check."
#~ msgstr ""
#~ "Если лицо не найдено, поворачивает изображения, чтобы попытаться найти "
#~ "лицо. Может найти больше лиц ценой снижения скорости извлечения. "
#~ "Передайте одно число, чтобы использовать приращения этого размера до 360, "
#~ "или передайте список чисел, чтобы перечислить, какие именно углы нужно "
#~ "проверить."

#~ msgid ""
#~ "Obtain and store face identity encodings from VGGFace2. Slows down "
#~ "extract a little, but will save time if using 'sort by face'"
#~ msgstr ""
#~ "Получение и хранение кодировок идентификации лица из VGGFace2. Немного "
#~ "замедляет извлечение, но экономит время при использовании \"сортировки по "
#~ "лицам\"."

#~ msgid "Face Processing"
#~ msgstr "Обработка лиц"

#~ msgid ""
#~ "Filters out faces detected below this size. Length, in pixels across the "
#~ "diagonal of the bounding box. Set to 0 for off"
#~ msgstr ""
#~ "Отфильтровывает лица, обнаруженные ниже этого размера. Длина в пикселях "
#~ "по диагонали ограничивающего поля. Установите значение 0, чтобы выключить"

#~ msgid ""
#~ "Optionally filter out people who you do not wish to extract by passing in "
#~ "images of those people. Should be a small variety of images at different "
#~ "angles and in different conditions. A folder containing the required "
#~ "images or multiple image files, space separated, can be selected."
#~ msgstr ""
#~ "По желанию отфильтруйте людей, которых вы не хотите извлекать, передав "
#~ "изображения этих людей. Должно быть небольшое разнообразие изображений "
#~ "под разными углами и в разных условиях. Можно выбрать папку, содержащую "
#~ "необходимые изображения, или несколько файлов изображений, разделенных "
#~ "пробелами."

#~ msgid ""
#~ "Optionally select people you wish to extract by passing in images of that "
#~ "person. Should be a small variety of images at different angles and in "
#~ "different conditions A folder containing the required images or multiple "
#~ "image files, space separated, can be selected."
#~ msgstr ""
#~ "По желанию выберите людей, которых вы хотите извлечь, передав изображения "
#~ "этого человека. Должно быть небольшое разнообразие изображений под "
#~ "разными углами и в разных условиях. Можно выбрать папку, содержащую "
#~ "необходимые изображения, или несколько файлов изображений, разделенных "
#~ "пробелами."

#~ msgid ""
#~ "For use with the optional nfilter/filter files. Threshold for positive "
#~ "face recognition. Higher values are stricter."
#~ msgstr ""
#~ "Для использования с дополнительными файлами nfilter/filter. Порог для "
#~ "положительного распознавания лица. Более высокие значения являются более "
#~ "строгими."

#~ msgid "output"
#~ msgstr "вывод"

#~ msgid ""
#~ "The output size of extracted faces. Make sure that the model you intend "
#~ "to train supports your required size. This will only need to be changed "
#~ "for hi-res models."
#~ msgstr ""
#~ "Выходной размер извлеченных лиц. Убедитесь, что модель, которую вы "
#~ "собираетесь тренировать, поддерживает требуемый размер. Это необходимо "
#~ "изменить только для моделей высокого разрешения."

#~ msgid ""
#~ "Extract every 'nth' frame. This option will skip frames when extracting "
#~ "faces. For example a value of 1 will extract faces from every frame, a "
#~ "value of 10 will extract faces from every 10th frame."
#~ msgstr ""
#~ "Извлекать каждый 'n-й' кадр. Этот параметр пропускает кадры при "
#~ "извлечении лиц. Например, значение 1 будет извлекать лица из каждого "
#~ "кадра, значение 10 будет извлекать лица из каждого 10-го кадра."

#~ msgid ""
#~ "Automatically save the alignments file after a set amount of frames. By "
#~ "default the alignments file is only saved at the end of the extraction "
#~ "process. NB: If extracting in 2 passes then the alignments file will only "
#~ "start to be saved out during the second pass. WARNING: Don't interrupt "
#~ "the script when writing the file because it might get corrupted. Set to 0 "
#~ "to turn off"
#~ msgstr ""
#~ "Автоматическое сохранение файла выравнивания после заданного количества "
#~ "кадров. По умолчанию файл выравнивания сохраняется только в конце "
#~ "процесса извлечения. Примечание: Если извлечение выполняется в 2 прохода, "
#~ "то файл выравнивания начнет сохраняться только во время второго прохода. "
#~ "ПРЕДУПРЕЖДЕНИЕ: Не прерывайте работу скрипта при записи файла, так как он "
#~ "может быть поврежден. Установите значение 0, чтобы отключить"

#~ msgid "Draw landmarks on the ouput faces for debugging purposes."
#~ msgstr "Нарисуйте ориентиры на выходящих гранях для отладки."

#~ msgid "settings"
#~ msgstr "настройки"

#~ msgid ""
#~ "Don't run extraction in parallel. Will run each part of the extraction "
#~ "process separately (one after the other) rather than all at the same "
#~ "time. Useful if VRAM is at a premium."
#~ msgstr ""
#~ "Не запускать извлечение параллельно. Каждая часть процесса извлечения "
#~ "будет выполняться отдельно (одна за другой), а не одновременно. Полезно, "
#~ "если память VRAM ограничена."

#~ msgid ""
#~ "Skips frames that have already been extracted and exist in the alignments "
#~ "file"
#~ msgstr ""
#~ "Пропускает кадры, которые уже были извлечены и существуют в файле "
#~ "выравнивания"

#~ msgid "Skip frames that already have detected faces in the alignments file"
#~ msgstr ""
#~ "Пропустить кадры, в которых уже есть обнаруженные лица в файле "
#~ "выравнивания"

#~ msgid ""
#~ "Skip saving the detected faces to disk. Just create an alignments file"
#~ msgstr ""
#~ "Не сохранять обнаруженные лица на диск. Просто создать файл выравнивания"

#~ msgid ""
#~ "Swap the original faces in a source video/images to your final faces.\n"
#~ "Conversion plugins can be configured in the 'Settings' Menu"
#~ msgstr ""
#~ "Поменять исходные лица в исходном видео/изображении на ваши конечные "
#~ "лица.\n"
#~ "Плагины конвертирования можно настроить в меню \"Настройки\""

#~ msgid ""
#~ "Only required if converting from images to video. Provide The original "
#~ "video that the source frames were extracted from (for extracting the fps "
#~ "and audio)."
#~ msgstr ""
#~ "Требуется только при преобразовании из изображений в видео. Предоставьте "
#~ "исходное видео, из которого были извлечены исходные кадры (для извлечения "
#~ "кадров в секунду и звука)."

#~ msgid ""
#~ "Model directory. The directory containing the trained model you wish to "
#~ "use for conversion."
#~ msgstr ""
#~ "Папка модели. Папка, содержащая обученную модель, которую вы хотите "
#~ "использовать для преобразования."

#~ msgid ""
#~ "R|Performs color adjustment to the swapped face. Some of these options "
#~ "have configurable settings in '/config/convert.ini' or 'Settings > "
#~ "Configure Convert Plugins':\n"
#~ "L|avg-color: Adjust the mean of each color channel in the swapped "
#~ "reconstruction to equal the mean of the masked area in the original "
#~ "image.\n"
#~ "L|color-transfer: Transfers the color distribution from the source to the "
#~ "target image using the mean and standard deviations of the L*a*b* color "
#~ "space.\n"
#~ "L|manual-balance: Manually adjust the balance of the image in a variety "
#~ "of color spaces. Best used with the Preview tool to set correct values.\n"
#~ "L|match-hist: Adjust the histogram of each color channel in the swapped "
#~ "reconstruction to equal the histogram of the masked area in the original "
#~ "image.\n"
#~ "L|seamless-clone: Use cv2's seamless clone function to remove extreme "
#~ "gradients at the mask seam by smoothing colors. Generally does not give "
#~ "very satisfactory results.\n"
#~ "L|none: Don't perform color adjustment."
#~ msgstr ""
#~ "R|Производит корректировку цвета поменявшегося лица. Некоторые из этих "
#~ "параметров настраиваются в '/config/convert.ini' или 'Настройки > "
#~ "Настроить плагины конвертации':\n"
#~ "L|avg-color: корректирует среднее значение каждого цветового канала в "
#~ "реконструкции, чтобы оно было равно среднему значению маскированной "
#~ "области в исходном изображении.\n"
#~ "L|color-transfer: Переносит распределение цветов с исходного изображения "
#~ "на целевое, используя среднее и стандартные отклонения цветового "
#~ "пространства L*a*b*.\n"
#~ "L|manual-balance: Ручная настройка баланса изображения в различных "
#~ "цветовых пространствах. Лучше всего использовать с инструментом "
#~ "предварительного просмотра для установки правильных значений.\n"
#~ "L|match-hist: Настроить гистограмму каждого цветового канала в измененном "
#~ "восстановлении так, чтобы она соответствовала гистограмме маскированной "
#~ "области исходного изображения.\n"
#~ "L|seamless-clone: Используйте функцию бесшовного клонирования cv2 для "
#~ "удаления экстремальных градиентов на шве маски путем сглаживания цветов. "
#~ "Обычно дает не очень удовлетворительные результаты.\n"
#~ "L|none: Не выполнять коррекцию цвета."

#~ msgid ""
#~ "R|Masker to use. NB: The mask you require must exist within the "
#~ "alignments file. You can add additional masks with the Mask Tool.\n"
#~ "L|none: Don't use a mask.\n"
#~ "L|bisenet-fp_face: Relatively lightweight NN based mask that provides "
#~ "more refined control over the area to be masked (configurable in mask "
#~ "settings). Use this version of bisenet-fp if your model is trained with "
#~ "'face' or 'legacy' centering.\n"
#~ "L|bisenet-fp_head: Relatively lightweight NN based mask that provides "
#~ "more refined control over the area to be masked (configurable in mask "
#~ "settings). Use this version of bisenet-fp if your model is trained with "
#~ "'head' centering.\n"
#~ "L|custom_face: Custom user created, face centered mask.\n"
#~ "L|custom_head: Custom user created, head centered mask.\n"
#~ "L|components: Mask designed to provide facial segmentation based on the "
#~ "positioning of landmark locations. A convex hull is constructed around "
#~ "the exterior of the landmarks to create a mask.\n"
#~ "L|extended: Mask designed to provide facial segmentation based on the "
#~ "positioning of landmark locations. A convex hull is constructed around "
#~ "the exterior of the landmarks and the mask is extended upwards onto the "
#~ "forehead.\n"
#~ "L|vgg-clear: Mask designed to provide smart segmentation of mostly "
#~ "frontal faces clear of obstructions. Profile faces and obstructions may "
#~ "result in sub-par performance.\n"
#~ "L|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
#~ "frontal faces. The mask model has been specifically trained to recognize "
#~ "some facial obstructions (hands and eyeglasses). Profile faces may result "
#~ "in sub-par performance.\n"
#~ "L|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
#~ "faces. The mask model has been trained by community members and will need "
#~ "testing for further description. Profile faces may result in sub-par "
#~ "performance.\n"
#~ "L|predicted: If the 'Learn Mask' option was enabled during training, this "
#~ "will use the mask that was created by the trained model."
#~ msgstr ""
#~ "R|Маскер для использования. Примечание: Нужная маска должна существовать "
#~ "в файле выравнивания. Вы можете добавить дополнительные маски с помощью "
#~ "инструмента Mask Tool.\n"
#~ "L|none: Не использовать маску.\n"
#~ "L|bisenet-fp_face: Относительно легкая маска на основе NN, которая "
#~ "обеспечивает более точный контроль над маскируемой областью "
#~ "(настраивается в настройках маски). Используйте эту версию bisenet-fp, "
#~ "если ваша модель обучена с центрированием 'face' или 'legacy'.\n"
#~ "L|bisenet-fp_head: Относительно легкая маска на основе NN, которая "
#~ "обеспечивает более точный контроль над маскируемой областью "
#~ "(настраивается в настройках маски). Используйте эту версию bisenet-fp, "
#~ "если ваша модель обучена с центрированием по \"голове\".\n"
#~ "L|custom_face: Пользовательская маска, созданная пользователем и "
#~ "центрированная по лицу.\n"
#~ "L|custom_head: Созданная пользователем маска, центрированная по голове.\n"
#~ "L|components: Маска, разработанная для сегментации лица на основе "
#~ "расположения ориентиров. Для создания маски вокруг внешних ориентиров "
#~ "строится выпуклая оболочка.\n"
#~ "L|extended: Маска, предназначенная для сегментации лица на основе "
#~ "расположения ориентиров. Выпуклый корпус строится вокруг внешних "
#~ "ориентиров, и маска расширяется вверх на лоб.\n"
#~ "L|vgg-clear: Маска предназначена для интеллектуальной сегментации "
#~ "преимущественно фронтальных лиц без препятствий. Профильные лица и "
#~ "препятствия могут привести к снижению производительности.\n"
#~ "L|vgg-obstructed: Маска, разработанная для интеллектуальной сегментации "
#~ "преимущественно фронтальных лиц. Модель маски была специально обучена "
#~ "распознавать некоторые препятствия на лице (руки и очки). Лица в профиль "
#~ "могут иметь низкую производительность.\n"
#~ "L|unet-dfl: Маска, разработанная для интеллектуальной сегментации "
#~ "преимущественно фронтальных лиц. Модель маски была обучена членами "
#~ "сообщества и для дальнейшего описания нуждается в тестировании. "
#~ "Профильные лица могут привести к низкой производительности.\n"
#~ "L|predicted: Если во время обучения была включена опция 'Изучить Маску', "
#~ "то будет использоваться маска, созданная обученной моделью."

#~ msgid ""
#~ "R|The plugin to use to output the converted images. The writers are "
#~ "configurable in '/config/convert.ini' or 'Settings > Configure Convert "
#~ "Plugins:'\n"
#~ "L|ffmpeg: [video] Writes out the convert straight to video. When the "
#~ "input is a series of images then the '-ref' (--reference-video) parameter "
#~ "must be set.\n"
#~ "L|gif: [animated image] Create an animated gif.\n"
#~ "L|opencv: [images] The fastest image writer, but less options and formats "
#~ "than other plugins.\n"
#~ "L|patch: [images] Outputs the raw swapped face patch, along with the "
#~ "transformation matrix required to re-insert the face back into the "
#~ "original frame. Use this option if you wish to post-process and composite "
#~ "the final face within external tools.\n"
#~ "L|pillow: [images] Slower than opencv, but has more options and supports "
#~ "more formats."
#~ msgstr ""
#~ "R|Плагин, который нужно использовать для вывода преобразованных "
#~ "изображений. Записи настраиваются в '/config/convert.ini' или 'Настройки "
#~ "> Настроить плагины конвертации:'\n"
#~ "L|ffmpeg: [видео] Записывает конвертацию прямо в видео. Если на вход "
#~ "подается серия изображений, необходимо установить параметр '-ref' (--"
#~ "reference-video).\n"
#~ "L|gif: [анимированное изображение] Создает анимированный gif.\n"
#~ "L|opencv: [изображения] Самый быстрый редактор изображений, но имеет "
#~ "меньше опций и форматов, чем другие плагины.\n"
#~ "L|patch: [изображения] Выводит необработанный фрагмент измененного лица "
#~ "вместе с матрицей преобразования, необходимой для повторной вставки лица "
#~ "обратно в исходный кадр.\n"
#~ "L|pillow: [изображения] Медленнее, чем opencv, но имеет больше опций и "
#~ "поддерживает больше форматов."

#~ msgid "Frame Processing"
#~ msgstr "Обработка лиц"

#, python-format
#~ msgid ""
#~ "Scale the final output frames by this amount. 100%% will output the "
#~ "frames at source dimensions. 50%% at half size 200%% at double size"
#~ msgstr ""
#~ "Масштабирование конечных выходных кадров на эту величину. 100%% выводит "
#~ "кадры в исходном размере. 50%% при половинном размере 200%% при двойном "
#~ "размере"

#~ msgid ""
#~ "Frame ranges to apply transfer to e.g. For frames 10 to 50 and 90 to 100 "
#~ "use --frame-ranges 10-50 90-100. Frames falling outside of the selected "
#~ "range will be discarded unless '-k' (--keep-unchanged) is selected. NB: "
#~ "If you are converting from images, then the filenames must end with the "
#~ "frame-number!"
#~ msgstr ""
#~ "Диапазоны кадров для применения переноса, например, для кадров с 10 по 50 "
#~ "и с 90 по 100 используйте --frame-ranges 10-50 90-100. Кадры, выходящие "
#~ "за пределы выбранного диапазона, будут отброшены, если не выбрана опция '-"
#~ "k' (--keep-unchanged). Примечание: Если вы конвертируете из изображений, "
#~ "то имена файлов должны заканчиваться номером кадра!"

#~ msgid ""
#~ "Scale the swapped face by this percentage. Positive values will enlarge "
#~ "the face, Negative values will shrink the face."
#~ msgstr ""
#~ "Увеличить масштаб нового лица на этот процент. Положительные значения "
#~ "увеличат лицо, в то время как отрицательные значения уменьшат его."

#~ msgid ""
#~ "If you have not cleansed your alignments file, then you can filter out "
#~ "faces by defining a folder here that contains the faces extracted from "
#~ "your input files/video. If this folder is defined, then only faces that "
#~ "exist within your alignments file and also exist within the specified "
#~ "folder will be converted. Leaving this blank will convert all faces that "
#~ "exist within the alignments file."
#~ msgstr ""
#~ "Если вы не очистили свой файл выравнивания, то вы можете отфильтровать "
#~ "лица, определив здесь папку, содержащую лица, извлеченные из ваших "
#~ "входных файлов/видео. Если эта папка определена, то будут преобразованы "
#~ "только те лица, которые существуют в вашем файле выравнивания, а также в "
#~ "указанной папке. Если оставить этот параметр пустым, будут преобразованы "
#~ "все лица, существующие в файле выравнивания."

#~ msgid ""
#~ "Optionally filter out people who you do not wish to process by passing in "
#~ "an image of that person. Should be a front portrait with a single person "
#~ "in the image. Multiple images can be added space separated. NB: Using "
#~ "face filter will significantly decrease extraction speed and its accuracy "
#~ "cannot be guaranteed."
#~ msgstr ""
#~ "По желанию отфильтровать людей, которых вы не хотите обрабатывать, "
#~ "передав изображение этого человека. Это должен быть фронтальный портрет с "
#~ "изображением одного человека. Можно добавить несколько изображений, "
#~ "разделенных пробелами. Примечание: Использование фильтра лиц значительно "
#~ "снизит скорость извлечения, а его точность не гарантируется."

#~ msgid ""
#~ "Optionally select people you wish to process by passing in an image of "
#~ "that person. Should be a front portrait with a single person in the "
#~ "image. Multiple images can be added space separated. NB: Using face "
#~ "filter will significantly decrease extraction speed and its accuracy "
#~ "cannot be guaranteed."
#~ msgstr ""
#~ "По желанию выберите людей, которых вы хотите обработать, передав "
#~ "изображение этого человека. Это должен быть фронтальный портрет с "
#~ "изображением одного человека. Можно добавить несколько изображений, "
#~ "разделенных пробелами. Примечание: Использование фильтра лиц значительно "
#~ "снизит скорость извлечения, а его точность не гарантируется."

#~ msgid ""
#~ "For use with the optional nfilter/filter files. Threshold for positive "
#~ "face recognition. Lower values are stricter. NB: Using face filter will "
#~ "significantly decrease extraction speed and its accuracy cannot be "
#~ "guaranteed."
#~ msgstr ""
#~ "Для использования с дополнительными файлами nfilter/filter. Порог для "
#~ "положительного распознавания лиц. Более низкие значения являются более "
#~ "строгими. Примечание: Использование фильтра лиц значительно снизит "
#~ "скорость извлечения, а его точность не гарантируется."

#~ msgid ""
#~ "The maximum number of parallel processes for performing conversion. "
#~ "Converting images is system RAM heavy so it is possible to run out of "
#~ "memory if you have a lot of processes and not enough RAM to accommodate "
#~ "them all. Setting this to 0 will use the maximum available. No matter "
#~ "what you set this to, it will never attempt to use more processes than "
#~ "are available on your system. If singleprocess is enabled this setting "
#~ "will be ignored."
#~ msgstr ""
#~ "Максимальное количество параллельных процессов для выполнения "
#~ "конвертации. Конвертирование изображений занимает много системной "
#~ "оперативной памяти, поэтому может закончиться память, если у вас много "
#~ "процессов и недостаточно оперативной памяти для их размещения. Если "
#~ "установить значение 0, будет использован максимум доступной памяти. "
#~ "Независимо от того, какое значение вы установите, программа никогда не "
#~ "будет пытаться использовать больше процессов, чем доступно в вашей "
#~ "системе. Если включена однопоточная обработка, этот параметр будет "
#~ "проигнорирован."

#~ msgid ""
#~ "[LEGACY] This only needs to be selected if a legacy model is being loaded "
#~ "or if there are multiple models in the model folder"
#~ msgstr ""
#~ "[ОТБРОШЕН] Этот параметр необходимо выбрать только в том случае, если "
#~ "загружается устаревшая модель или если в папке моделей имеется несколько "
#~ "моделей"

#~ msgid ""
#~ "Enable On-The-Fly Conversion. NOT recommended. You should generate a "
#~ "clean alignments file for your destination video. However, if you wish "
#~ "you can generate the alignments on-the-fly by enabling this option. This "
#~ "will use an inferior extraction pipeline and will lead to substandard "
#~ "results. If an alignments file is found, this option will be ignored."
#~ msgstr ""
#~ "Включить преобразование \"на лету\". НЕ рекомендуется. Вы должны "
#~ "сгенерировать чистый файл выравнивания для конечного видео. Однако при "
#~ "желании вы можете генерировать выравнивания \"на лету\", включив эту "
#~ "опцию. При этом будет использоваться некачественный конвейер извлечения, "
#~ "что приведет к некачественным результатам. Если файл выравнивания найден, "
#~ "этот параметр будет проигнорирован."

#~ msgid ""
#~ "When used with --frame-ranges outputs the unchanged frames that are not "
#~ "processed instead of discarding them."
#~ msgstr ""
#~ "При использовании с --frame-ranges выводит неизмененные кадры, которые не "
#~ "были обработаны, вместо того, чтобы отбрасывать их."

#~ msgid "Swap the model. Instead converting from of A -> B, converts B -> A"
#~ msgstr ""
#~ "Поменять модель местами. Вместо преобразования из A -> B, преобразуется B "
#~ "-> A"

#~ msgid "Disable multiprocessing. Slower but less resource intensive."
#~ msgstr ""
#~ "Отключение многопоточной обработки. Медленнее, но менее ресурсоемко."

#~ msgid "Output to Shell console instead of GUI console"
#~ msgstr "Вывод в консоль Shell вместо консоли GUI"

#~ msgid ""
#~ "[Deprecated - Use '-D, --distribution-strategy' instead] Use the "
#~ "Tensorflow Mirrored Distrubution Strategy to train on multiple GPUs."
#~ msgstr ""
#~ "[Устарело - Используйте '-D, --distribution-strategy' вместо этого] "
#~ "Используйте стратегию Tensorflow Mirrored Distrubution Strategy(Стратегия "
#~ "Зеркального Распределения Tensorflow) для обучения на нескольких GPU."
