# SOME DESCRIPTIVE TITLE.
# Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-03-28 18:11+0000\n"
"PO-Revision-Date: 2024-03-28 18:16+0000\n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: ko_KR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Poedit 3.4.2\n"

#: lib/cli/args_extract_convert.py:46 lib/cli/args_extract_convert.py:56
#: lib/cli/args_extract_convert.py:64 lib/cli/args_extract_convert.py:122
#: lib/cli/args_extract_convert.py:479 lib/cli/args_extract_convert.py:488
msgid "Data"
msgstr "데이터"

#: lib/cli/args_extract_convert.py:48
msgid ""
"Input directory or video. Either a directory containing the image files you "
"wish to process or path to a video file. NB: This should be the source video/"
"frames NOT the source faces."
msgstr ""
"폴더나 비디오를 입력하세요. 당신이 사용하고 싶은 이미지 파일들을 가진 폴더 또"
"는 비디오 파일의 경로여야 합니다. NB: 이 폴더는 원본 비디오여야 합니다."

#: lib/cli/args_extract_convert.py:57
msgid "Output directory. This is where the converted files will be saved."
msgstr "출력 폴더. 변환된 파일들이 저장될 곳입니다."

#: lib/cli/args_extract_convert.py:66
msgid ""
"Optional path to an alignments file. Leave blank if the alignments file is "
"at the default location."
msgstr ""
"(선택적) alignments 파일의 경로. 비워두면 alignments 파일이 기본 위치에 저장"
"됩니다."

#: lib/cli/args_extract_convert.py:97
msgid ""
"Extract faces from image or video sources.\n"
"Extraction plugins can be configured in the 'Settings' Menu"
msgstr ""
"얼굴들을 이미지 또는 비디오에서 추출합니다.\n"
"추출 플러그인은 '설정' 메뉴에서 설정할 수 있습니다"

#: lib/cli/args_extract_convert.py:124
msgid ""
"R|If selected then the input_dir should be a parent folder containing "
"multiple videos and/or folders of images you wish to extract from. The faces "
"will be output to separate sub-folders in the output_dir."
msgstr ""
"R|만약 선택된다면 input_dir은 당신이 추출하고자 하는 여러개의 비디오 그리고/"
"또는 이미지들을 가진 부모 폴더가 되야 합니다. 얼굴들은 output_dir에 분리된 하"
"위 폴더에 저장됩니다."

#: lib/cli/args_extract_convert.py:133 lib/cli/args_extract_convert.py:150
#: lib/cli/args_extract_convert.py:163 lib/cli/args_extract_convert.py:202
#: lib/cli/args_extract_convert.py:220 lib/cli/args_extract_convert.py:233
#: lib/cli/args_extract_convert.py:243 lib/cli/args_extract_convert.py:253
#: lib/cli/args_extract_convert.py:499 lib/cli/args_extract_convert.py:525
#: lib/cli/args_extract_convert.py:564
msgid "Plugins"
msgstr "플러그인들"

#: lib/cli/args_extract_convert.py:135
msgid ""
"R|Detector to use. Some of these have configurable settings in '/config/"
"extract.ini' or 'Settings > Configure Extract 'Plugins':\n"
"L|cv2-dnn: A CPU only extractor which is the least reliable and least "
"resource intensive. Use this if not using a GPU and time is important.\n"
"L|mtcnn: Good detector. Fast on CPU, faster on GPU. Uses fewer resources "
"than other GPU detectors but can often return more false positives.\n"
"L|s3fd: Best detector. Slow on CPU, faster on GPU. Can detect more faces and "
"fewer false positives than other GPU detectors, but is a lot more resource "
"intensive."
msgstr ""
"R|사용할 감지기. 몇몇 감지기들은 '/config/extract.ini' 또는 '설정 > 추출 플러"
"그인 설정'에서 설정이 가능합니다:\n"
"L|cv2-dnn: 가장 믿을 수 없고 가장 자원을 덜 사용하며 CPU만을 사용하는 추출기"
"입니다. 만약 GPU를 사용하지 않고 시간이 중요하다면 사용하세요.\n"
"L|mtcnn: 좋은 감지기. CPU에서도 빠르고 GPU에서도 빠릅니다. 다른 GPU 감지기들"
"보다 더 적은 자원을 사용하지만 가끔 더 많은 false positives를 돌려줄 수 있습"
"니다.\n"
"L|s3fd: 가장 좋은 감지기. CPU에선 느리고 GPU에선 빠릅니다. 다른 GPU 감지기들"
"보다 더 많은 얼굴들을 감지할 수 있고 과 더 적은 false positives를 돌려주지만 "
"자원을 굉장히 많이 사용합니다."

#: lib/cli/args_extract_convert.py:152
msgid ""
"R|Aligner to use.\n"
"L|cv2-dnn: A CPU only landmark detector. Faster, less resource intensive, "
"but less accurate. Only use this if not using a GPU and time is important.\n"
"L|fan: Best aligner. Fast on GPU, slow on CPU."
msgstr ""
"R|사용할 Aligner.\n"
"L|cv2-dnn: CPU만을 사용하는 특징점 감지기. 빠르고 자원을 덜 사용하지만 부정확"
"합니다. GPU를 사용하지 않고 시간이 중요할 때에만 사용하세요.\n"
"L|fan: 가장 좋은 aligner. GPU에선 빠르고 CPU에선 느립니다."

#: lib/cli/args_extract_convert.py:165
msgid ""
"R|Additional Masker(s) to use. The masks generated here will all take up GPU "
"RAM. You can select none, one or multiple masks, but the extraction may take "
"longer the more you select. NB: The Extended and Components (landmark based) "
"masks are automatically generated on extraction.\n"
"L|bisenet-fp: Relatively lightweight NN based mask that provides more "
"refined control over the area to be masked including full head masking "
"(configurable in mask settings).\n"
"L|custom: A dummy mask that fills the mask area with all 1s or 0s "
"(configurable in settings). This is only required if you intend to manually "
"edit the custom masks yourself in the manual tool. This mask does not use "
"the GPU so will not use any additional VRAM.\n"
"L|vgg-clear: Mask designed to provide smart segmentation of mostly frontal "
"faces clear of obstructions. Profile faces and obstructions may result in "
"sub-par performance.\n"
"L|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
"frontal faces. The mask model has been specifically trained to recognize "
"some facial obstructions (hands and eyeglasses). Profile faces may result in "
"sub-par performance.\n"
"L|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
"faces. The mask model has been trained by community members and will need "
"testing for further description. Profile faces may result in sub-par "
"performance.\n"
"The auto generated masks are as follows:\n"
"L|components: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks to create a mask.\n"
"L|extended: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks and the mask is extended upwards onto the "
"forehead.\n"
"(eg: `-M unet-dfl vgg-clear`, `--masker vgg-obstructed`)"
msgstr ""
"R|사용할 추가 Mask입니다. 여기서 생성된 마스크는 모두 GPU RAM을 차지합니다. "
"마스크를 0개, 1개 또는 여러 개 선택할 수 있지만 더 많이 선택할수록 추출에 시"
"간이 더 걸릴 수 있습니다. NB: 확장 및 구성 요소(특징점 기반) 마스크는 추출 "
"시 자동으로 생성됩니다.\n"
"L|bisnet-fp: 전체 헤드 마스킹(마스크 설정에서 구성 가능)을 포함하여 마스킹할 "
"영역에 대한 보다 정교한 제어를 제공하는 비교적 가벼운 NN 기반 마스크입니다.\n"
"L|custom: 마스크 영역을 모든 1 또는 0으로 채우는 dummy 마스크입니다(설정에서 "
"구성 가능). 수동 도구에서 사용자 정의 마스크를 직접 수동으로 편집하려는 경우"
"에만 필요합니다. 이 마스크는 GPU를 사용하지 않으므로 추가 VRAM을 사용하지 않"
"습니다.\n"
"L|vgg-clear: 대부분의 정면에 장애물이 없는 스마트한 분할을 제공하도록 설계된 "
"마스크입니다. 프로필 얼굴들 및 장애물들로 인해 성능이 저하될 수 있습니다.\n"
"L|vgg-obstructed: 대부분의 정면 얼굴을 스마트하게 분할할 수 있도록 설계된 마"
"스크입니다. 마스크 모델은 일부 안면 장애물(손과 안경)을 인식하도록 특별히 훈"
"련되었습니다. 프로필 얼굴들은 평균 이하의 성능을 초래할 수 있습니다.\n"
"L|unet-dfl: 대부분 정면 얼굴을 스마트하게 분할하도록 설계된 마스크. 마스크 모"
"델은 커뮤니티 구성원들에 의해 훈련되었으며 추가 설명을 위해 테스트가 필요하"
"다. 프로필 얼굴들은 평균 이하의 성능을 초래할 수 있습니다.\n"
"자동 생성 마스크는 다음과 같습니다.\n"
"L|components: 특징점 위치의 위치를 기반으로 얼굴 분할을 제공하도록 설계된 마"
"스크입니다. 특징점의 외부에는 마스크를 만들기 위해 convex hull가 형성되어 있"
"습니다.\n"
"L|extended: 특징점 위치의 위치를 기반으로 얼굴 분할을 제공하도록 설계된 마스"
"크입니다. 특징점의 외부에는 convex hull가 형성되어 있으며, 마스크는 이마 위"
"로 뻗어 있습ㄴ다.\n"
"(예: '-M unet-dfl vgg-clear', '--masker vgg-obstructed')"

#: lib/cli/args_extract_convert.py:204
msgid ""
"R|Performing normalization can help the aligner better align faces with "
"difficult lighting conditions at an extraction speed cost. Different methods "
"will yield different results on different sets. NB: This does not impact the "
"output face, just the input to the aligner.\n"
"L|none: Don't perform normalization on the face.\n"
"L|clahe: Perform Contrast Limited Adaptive Histogram Equalization on the "
"face.\n"
"L|hist: Equalize the histograms on the RGB channels.\n"
"L|mean: Normalize the face colors to the mean."
msgstr ""
"R|정규화를 수행하면 aligner가 추출 속도 비용으로 어려운 조명 조건의 얼굴을 "
"더 잘 정렬할 수 있습니다. 방법이 다르면 세트마다 결과가 다릅니다. NB: 출력 얼"
"굴에는 영향을 주지 않으며 aligner에 대한 입력에만 영향을 줍니다.\n"
"L|none: 얼굴에 정규화를 수행하지 마십시오.\n"
"L|clahe: 얼굴에 Contrast Limited Adaptive Histogram Equalization를 수행합니"
"다.\n"
"L|hist: RGB 채널의 히스토그램을 동일하게 합니다.\n"
"L|mean: 얼굴 색상을 평균으로 정규화합니다."

#: lib/cli/args_extract_convert.py:222
msgid ""
"The number of times to re-feed the detected face into the aligner. Each time "
"the face is re-fed into the aligner the bounding box is adjusted by a small "
"amount. The final landmarks are then averaged from each iteration. Helps to "
"remove 'micro-jitter' but at the cost of slower extraction speed. The more "
"times the face is re-fed into the aligner, the less micro-jitter should "
"occur but the longer extraction will take."
msgstr ""
"검출된 얼굴을 aligner에 다시 공급하는 횟수입니다. 얼굴이 aligner에 다시 공급"
"될 때마다 경계 상자가 소량 조정됩니다. 그런 다음 각 반복에서 최종 특징점의 평"
"균을 구한다. 'micro-jitter'를 제거하는 데 도움이 되지만 추출 속도가 느려집니"
"다. 얼굴이 aligner에 다시 공급되는 횟수가 많을수록 micro-jitter 적게 발생하지"
"만 추출에 더 오랜 시간이 걸립니다."

#: lib/cli/args_extract_convert.py:235
msgid ""
"Re-feed the initially found aligned face through the aligner. Can help "
"produce better alignments for faces that are rotated beyond 45 degrees in "
"the frame or are at extreme angles. Slows down extraction."
msgstr ""
"_aligner를 통해 처음 발견된 정렬된 얼굴을 재공급합니다. 프레임에서 45도 이상 "
"회전하거나 극단적인 각도에 있는 얼굴을 더 잘 정렬할 수 있습니다. 추출 속도가 "
"느려집니다."

#: lib/cli/args_extract_convert.py:245
msgid ""
"If a face isn't found, rotate the images to try to find a face. Can find "
"more faces at the cost of extraction speed. Pass in a single number to use "
"increments of that size up to 360, or pass in a list of numbers to enumerate "
"exactly what angles to check."
msgstr ""
"얼굴이 발견되지 않으면 이미지를 회전하여 얼굴을 찾습니다. 추출 속도를 희생하"
"면서 더 많은 얼굴을 찾을 수 있습니다. 단일 숫자를 입력하여 해당 크기의 증분"
"을 360까지 사용하거나 숫자 목록을 입력하여 확인할 각도를 정확하게 열거합니다."

#: lib/cli/args_extract_convert.py:255
msgid ""
"Obtain and store face identity encodings from VGGFace2. Slows down extract a "
"little, but will save time if using 'sort by face'"
msgstr ""
"VGGFace2에서 얼굴 식별 인코딩을 가져와 저장합니다. 추출 속도를 약간 늦추지만 "
"'얼굴별로 정렬'을 사용하면 시간을 절약할 수 있습니다."

#: lib/cli/args_extract_convert.py:265 lib/cli/args_extract_convert.py:276
#: lib/cli/args_extract_convert.py:289 lib/cli/args_extract_convert.py:303
#: lib/cli/args_extract_convert.py:610 lib/cli/args_extract_convert.py:619
#: lib/cli/args_extract_convert.py:634 lib/cli/args_extract_convert.py:647
#: lib/cli/args_extract_convert.py:661
msgid "Face Processing"
msgstr "얼굴 처리"

#: lib/cli/args_extract_convert.py:267
msgid ""
"Filters out faces detected below this size. Length, in pixels across the "
"diagonal of the bounding box. Set to 0 for off"
msgstr ""
"이 크기 미만으로 탐지된 얼굴을 필터링합니다. 길이, 경계 상자의 대각선에 걸친 "
"픽셀 단위입니다. 0으로 설정하면 꺼집니다"

#: lib/cli/args_extract_convert.py:278
msgid ""
"Optionally filter out people who you do not wish to extract by passing in "
"images of those people. Should be a small variety of images at different "
"angles and in different conditions. A folder containing the required images "
"or multiple image files, space separated, can be selected."
msgstr ""
"선택적으로 추출하지 않을 사람의 이미지들을 전달하여 그 사람들을 제외합니다. "
"각도와 조건이 다른 작은 다양한 이미지여야 합니다. 추출되지 않는데 필요한 이미"
"지들 또는 공백으로 구분된 여러 이미지 파일이 들어 있는 폴더를 선택할 수 있습"
"니다."

#: lib/cli/args_extract_convert.py:291
msgid ""
"Optionally select people you wish to extract by passing in images of that "
"person. Should be a small variety of images at different angles and in "
"different conditions A folder containing the required images or multiple "
"image files, space separated, can be selected."
msgstr ""
"선택적으로 추출하고 싶은 사람의 이미지를 전달하여 그 사람을 선택합니다. 각도"
"와 조건이 다른 작은 다양한 이미지여야 합니다. 추출할 때 필요한 이미지들 또는 "
"공백으로 구분된 여러 이미지 파일이 들어 있는 폴더를 선택할 수 있습니다."

#: lib/cli/args_extract_convert.py:305
msgid ""
"For use with the optional nfilter/filter files. Threshold for positive face "
"recognition. Higher values are stricter."
msgstr ""
"옵션인 nfilter/filter 파일과 함께 사용합니다. 긍정적인 얼굴 인식을 위한 임계"
"값. 값이 높을수록 엄격합니다."

#: lib/cli/args_extract_convert.py:314 lib/cli/args_extract_convert.py:327
#: lib/cli/args_extract_convert.py:340 lib/cli/args_extract_convert.py:352
msgid "output"
msgstr "출력"

#: lib/cli/args_extract_convert.py:316
msgid ""
"The output size of extracted faces. Make sure that the model you intend to "
"train supports your required size. This will only need to be changed for hi-"
"res models."
msgstr ""
"추출된 얼굴의 출력 크기입니다. 훈련하려는 모델이 필요한 크기를 지원하는지 꼭 "
"확인하세요. 이것은 고해상도 모델에 대해서만 변경하면 됩니다."

#: lib/cli/args_extract_convert.py:329
msgid ""
"Extract every 'nth' frame. This option will skip frames when extracting "
"faces. For example a value of 1 will extract faces from every frame, a value "
"of 10 will extract faces from every 10th frame."
msgstr ""
"모든 'n번째' 프레임을 추출합니다. 이 옵션은 얼굴을 추출할 때 건너뛸 프레임을 "
"설정합니다. 예를 들어, 값이 1이면 모든 프레임에서 얼굴이 추출되고, 값이 10이"
"면 모든 10번째 프레임에서 얼굴이 추출됩니다."

#: lib/cli/args_extract_convert.py:342
msgid ""
"Automatically save the alignments file after a set amount of frames. By "
"default the alignments file is only saved at the end of the extraction "
"process. NB: If extracting in 2 passes then the alignments file will only "
"start to be saved out during the second pass. WARNING: Don't interrupt the "
"script when writing the file because it might get corrupted. Set to 0 to "
"turn off"
msgstr ""
"프레임 수가 설정된 후 alignments 파일을 자동으로 저장합니다. 기본적으로 "
"alignments 파일은 추출 프로세스가 끝날 때만 저장됩니다. NB: 2번째 추출에서 성"
"공하면 두 번째 추출 중에만 alignments 파일이 저장되기 시작합니다. 경고: 파일"
"을 쓸 때 스크립트가 손상될 수 있으므로 스크립트를 중단하지 마십시오. 해제하려"
"면 0으로 설정"

#: lib/cli/args_extract_convert.py:353
msgid "Draw landmarks on the ouput faces for debugging purposes."
msgstr "디버깅을 위해 출력 얼굴에 특징점을 그립니다."

#: lib/cli/args_extract_convert.py:359 lib/cli/args_extract_convert.py:369
#: lib/cli/args_extract_convert.py:377 lib/cli/args_extract_convert.py:384
#: lib/cli/args_extract_convert.py:674 lib/cli/args_extract_convert.py:686
#: lib/cli/args_extract_convert.py:695 lib/cli/args_extract_convert.py:716
#: lib/cli/args_extract_convert.py:722
msgid "settings"
msgstr "설정"

#: lib/cli/args_extract_convert.py:361
msgid ""
"Don't run extraction in parallel. Will run each part of the extraction "
"process separately (one after the other) rather than all at the same time. "
"Useful if VRAM is at a premium."
msgstr ""
"추출을 병렬로 실행하지 마십시오. 추출 프로세스의 각 부분을 동시에 모두 실행하"
"는 것이 아니라 개별적으로(하나씩) 실행합니다. VRAM이 프리미엄인 경우 유용합니"
"다."

#: lib/cli/args_extract_convert.py:371
msgid ""
"Skips frames that have already been extracted and exist in the alignments "
"file"
msgstr "이미 추출되었거나 alignments 파일에 존재하는 프레임들을 스킵합니다"

#: lib/cli/args_extract_convert.py:378
msgid "Skip frames that already have detected faces in the alignments file"
msgstr "이미 얼굴을 탐지하여 alignments 파일에 존재하는 프레임들을 스킵합니다"

#: lib/cli/args_extract_convert.py:385
msgid "Skip saving the detected faces to disk. Just create an alignments file"
msgstr ""
"탐지된 얼굴을 디스크에 저장하지 않습니다. 그저 alignments 파일을 만듭니다"

#: lib/cli/args_extract_convert.py:459
msgid ""
"Swap the original faces in a source video/images to your final faces.\n"
"Conversion plugins can be configured in the 'Settings' Menu"
msgstr ""
"원본 비디오/이미지의 원래 얼굴을 최종 얼굴으로 바꿉니다.\n"
"변환 플러그인은 '설정' 메뉴에서 구성할 수 있습니다"

#: lib/cli/args_extract_convert.py:481
msgid ""
"Only required if converting from images to video. Provide The original video "
"that the source frames were extracted from (for extracting the fps and "
"audio)."
msgstr ""
"이미지에서 비디오로 변환하는 경우에만 필요합니다. 소스 프레임이 추출된 원본 "
"비디오(fps 및 오디오 추출용)를 입력하세요."

#: lib/cli/args_extract_convert.py:490
msgid ""
"Model directory. The directory containing the trained model you wish to use "
"for conversion."
msgstr ""
"모델 폴더. 당신이 변환에 사용하고자 하는 훈련된 모델을 가진 폴더입니다."

#: lib/cli/args_extract_convert.py:501
msgid ""
"R|Performs color adjustment to the swapped face. Some of these options have "
"configurable settings in '/config/convert.ini' or 'Settings > Configure "
"Convert Plugins':\n"
"L|avg-color: Adjust the mean of each color channel in the swapped "
"reconstruction to equal the mean of the masked area in the original image.\n"
"L|color-transfer: Transfers the color distribution from the source to the "
"target image using the mean and standard deviations of the L*a*b* color "
"space.\n"
"L|manual-balance: Manually adjust the balance of the image in a variety of "
"color spaces. Best used with the Preview tool to set correct values.\n"
"L|match-hist: Adjust the histogram of each color channel in the swapped "
"reconstruction to equal the histogram of the masked area in the original "
"image.\n"
"L|seamless-clone: Use cv2's seamless clone function to remove extreme "
"gradients at the mask seam by smoothing colors. Generally does not give very "
"satisfactory results.\n"
"L|none: Don't perform color adjustment."
msgstr ""
"R|스왑된 얼굴의 색상 조정을 수행합니다. 이러한 옵션 중 일부에는 '/config/"
"convert.ini' 또는 '설정 > 변환 플러그인 구성'에서 구성 가능한 설정이 있습니"
"다.\n"
"L|avg-color: 스왑된 재구성에서 각 색상 채널의 평균이 원본 영상에서 마스킹된 "
"영역의 평균과 동일하도록 조정합니다.\n"
"L|color-transfer: L*a*b* 색 공간의 평균 및 표준 편차를 사용하여 소스에서 대"
"상 이미지로 색 분포를 전송합니다.\n"
"L|manual-balance: 다양한 색 공간에서 이미지의 밸런스를 수동으로 조정합니다. "
"올바른 값을 설정하려면 미리 보기 도구와 함께 사용하는 것이 좋습니다.\n"
"L|match-hist: 스왑된 재구성에서 각 색상 채널의 히스토그램을 조정하여 원래 영"
"상에서 마스킹된 영역의 히스토그램과 동일하게 만듭니다.\n"
"L|seamless-clone: cv2의 원활한 복제 기능을 사용하여 색상을 평활화하여 마스크 "
"심에서 극단적인 gradients을 제거합니다. 일반적으로 매우 만족스러운 결과를 제"
"공하지 않습니다.\n"
"L|none: 색상 조정을 수행하지 않습니다."

#: lib/cli/args_extract_convert.py:527
msgid ""
"R|Masker to use. NB: The mask you require must exist within the alignments "
"file. You can add additional masks with the Mask Tool.\n"
"L|none: Don't use a mask.\n"
"L|bisenet-fp_face: Relatively lightweight NN based mask that provides more "
"refined control over the area to be masked (configurable in mask settings). "
"Use this version of bisenet-fp if your model is trained with 'face' or "
"'legacy' centering.\n"
"L|bisenet-fp_head: Relatively lightweight NN based mask that provides more "
"refined control over the area to be masked (configurable in mask settings). "
"Use this version of bisenet-fp if your model is trained with 'head' "
"centering.\n"
"L|custom_face: Custom user created, face centered mask.\n"
"L|custom_head: Custom user created, head centered mask.\n"
"L|components: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks to create a mask.\n"
"L|extended: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks and the mask is extended upwards onto the "
"forehead.\n"
"L|vgg-clear: Mask designed to provide smart segmentation of mostly frontal "
"faces clear of obstructions. Profile faces and obstructions may result in "
"sub-par performance.\n"
"L|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
"frontal faces. The mask model has been specifically trained to recognize "
"some facial obstructions (hands and eyeglasses). Profile faces may result in "
"sub-par performance.\n"
"L|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
"faces. The mask model has been trained by community members and will need "
"testing for further description. Profile faces may result in sub-par "
"performance.\n"
"L|predicted: If the 'Learn Mask' option was enabled during training, this "
"will use the mask that was created by the trained model."
msgstr ""
"R|사용할 마스크. NB: 필요한 마스크는 alignments 파일 내에 있어야 합니다. 마스"
"크 도구를 사용하여 마스크를 추가할 수 있습니다.\n"
"L|none: 마스크 쓰지 마세요.\n"
"L|bisnet-fp_face: 마스크할 영역을 보다 정교하게 제어할 수 있는 비교적 가벼운 "
"NN 기반 마스크입니다(마스크 설정에서 구성 가능). 모델이 '얼굴' 또는 '레거시' "
"중심으로 훈련된 경우 이 버전의 bisnet-fp를 사용하십시오.\n"
"L|bisnet-fp_head: 마스크할 영역을 보다 정교하게 제어할 수 있는 비교적 가벼운 "
"NN 기반 마스크입니다(마스크 설정에서 구성 가능). 모델이 '헤드' 중심으로 훈련"
"된 경우 이 버전의 bisnet-fp를 사용하십시오.\n"
"L|custom_face: 사용자 지정 사용자가 생성한 얼굴 중심 마스크입니다.\n"
"L|custom_head: 사용자 지정 사용자가 생성한 머리 중심 마스크입니다.\n"
"L|components: 특징점 위치의 배치를 기반으로 얼굴 분할을 제공하도록 설계된 마"
"스크입니다. 특징점의 외부에는 마스크를 만들기 위해 convex hull가 형성되어 있"
"습니다.\n"
"L|extended: 특징점 위치의 배치를 기반으로 얼굴 분할을 제공하도록 설계된 마스"
"크입니다. 지형지물의 외부에는 convex hull가 형성되어 있으며, 마스크는 이마 위"
"로 뻗어 있습니다.\n"
"L|vgg-clear: 대부분의 정면에 장애물이 없는 스마트한 분할을 제공하도록 설계된 "
"마스크입니다. 옆 얼굴 및 장애물로 인해 성능이 저하될 수 있습니다.\n"
"L|vgg-obstructed: 대부분의 정면 얼굴을 스마트하게 분할할 수 있도록 설계된 마"
"스크입니다. 마스크 모델은 일부 안면 장애물(손과 안경)을 인식하도록 특별히 훈"
"련되었습니다. 옆 얼굴은 평균 이하의 성능을 초래할 수 있습니다.\n"
"L|unet-dfl: 대부분 정면 얼굴을 스마트하게 분할하도록 설계된 마스크. 마스크 모"
"델은 커뮤니티 구성원들에 의해 훈련되었으며 추가 설명을 위해 테스트가 필요하"
"다. 옆 얼굴은 평균 이하의 성능을 초래할 수 있습니다.\n"
"L|predicted: 교육 중에 'Learn Mask(마스크 학습)' 옵션이 활성화된 경우에는 교"
"육을 받은 모델이 만든 마스크가 사용됩니다."

#: lib/cli/args_extract_convert.py:566
msgid ""
"R|The plugin to use to output the converted images. The writers are "
"configurable in '/config/convert.ini' or 'Settings > Configure Convert "
"Plugins:'\n"
"L|ffmpeg: [video] Writes out the convert straight to video. When the input "
"is a series of images then the '-ref' (--reference-video) parameter must be "
"set.\n"
"L|gif: [animated image] Create an animated gif.\n"
"L|opencv: [images] The fastest image writer, but less options and formats "
"than other plugins.\n"
"L|patch: [images] Outputs the raw swapped face patch, along with the "
"transformation matrix required to re-insert the face back into the original "
"frame. Use this option if you wish to post-process and composite the final "
"face within external tools.\n"
"L|pillow: [images] Slower than opencv, but has more options and supports "
"more formats."
msgstr ""
"R|변환된 이미지를 출력하는 데 사용할 플러그인입니다. 기록 장치는 '/config/"
"convert.ini' 또는 '설정 > 변환 플러그인 구성:'에서 구성할 수 있습니다.\n"
"L|ffmpeg: [video] 변환된 결과를 바로 video로 씁니다. 입력이 영상 시리즈인 경"
"우 '-ref'(--reference-video) 파라미터를 설정해야 합니다.\n"
"L|gif : [애니메이션 이미지] 애니메이션 gif를 만듭니다.\n"
"L|opencv: [이미지] 가장 빠른 이미지 작성기이지만 다른 플러그인에 비해 옵션과 "
"형식이 적습니다.\n"
"L|patch: [이미지] 원래 프레임에 얼굴을 다시 삽입하는 데 필요한 변환 행렬과 함"
"께 원시 교체된 얼굴 패치를 출력합니다.\n"
"L|pillow: [images] opencv보다 느리지만 더 많은 옵션이 있고 더 많은 형식을 지"
"원합니다."

#: lib/cli/args_extract_convert.py:587 lib/cli/args_extract_convert.py:596
#: lib/cli/args_extract_convert.py:707
msgid "Frame Processing"
msgstr "프레임 처리"

#: lib/cli/args_extract_convert.py:589
#, python-format
msgid ""
"Scale the final output frames by this amount. 100%% will output the frames "
"at source dimensions. 50%% at half size 200%% at double size"
msgstr ""
"최종 출력 프레임의 크기를 이 양만큼 조정합니다. 100%%는 원본의 차원에서 프레"
"임을 출력합니다. 50%%는 절반 크기에서, 200%%는 두 배 크기에서"

#: lib/cli/args_extract_convert.py:598
msgid ""
"Frame ranges to apply transfer to e.g. For frames 10 to 50 and 90 to 100 use "
"--frame-ranges 10-50 90-100. Frames falling outside of the selected range "
"will be discarded unless '-k' (--keep-unchanged) is selected. NB: If you are "
"converting from images, then the filenames must end with the frame-number!"
msgstr ""
"예를 들어 전송을 적용할 프레임 범위 프레임 10 - 50 및 90 - 100의 경우 --"
"frame-ranges 10-50 90-100을 사용합니다. '-k'(--keep-unchanged)를 선택하지 않"
"으면 선택한 범위를 벗어나는 프레임이 삭제됩니다. NB: 이미지에서 변환하는 경"
"우 파일 이름은 프레임 번호로 끝나야 합니다!"

#: lib/cli/args_extract_convert.py:612
msgid ""
"Scale the swapped face by this percentage. Positive values will enlarge the "
"face, Negative values will shrink the face."
msgstr ""
"이 백분율로 교체된 면의 크기를 조정합니다. 양수 값은 얼굴을 확대하고, 음수 값"
"은 얼굴을 축소합니다."

#: lib/cli/args_extract_convert.py:621
msgid ""
"If you have not cleansed your alignments file, then you can filter out faces "
"by defining a folder here that contains the faces extracted from your input "
"files/video. If this folder is defined, then only faces that exist within "
"your alignments file and also exist within the specified folder will be "
"converted. Leaving this blank will convert all faces that exist within the "
"alignments file."
msgstr ""
"만약 alignments 파일을 지우지 않은 경우 입력 파일/비디오에서 추출된 얼굴이 포"
"함된 폴더를 정의하여 얼굴을 걸러낼 수 있습니다. 이 폴더가 정의된 경우 "
"alignments 파일 내에 존재하거나 지정된 폴더 내에 존재하는 얼굴만 변환됩니다. "
"이 항목을 공백으로 두면 alignments 파일 내에 있는 모든 얼굴이 변환됩니다."

#: lib/cli/args_extract_convert.py:636
msgid ""
"Optionally filter out people who you do not wish to process by passing in an "
"image of that person. Should be a front portrait with a single person in the "
"image. Multiple images can be added space separated. NB: Using face filter "
"will significantly decrease extraction speed and its accuracy cannot be "
"guaranteed."
msgstr ""
"선택적으로 처리하고 싶지 않은 사람의 이미지를 전달하여 그 사람을 걸러낼 수 있"
"습니다. 이미지는 한 사람의 정면 모습이여야 합니다. 여러 이미지를 공백으로 구"
"분하여 추가할 수 있습니다. 주의: 얼굴 필터를 사용하면 추출 속도가 현저히 감소"
"하므로 정확성을 보장할 수 없습니다."

#: lib/cli/args_extract_convert.py:649
msgid ""
"Optionally select people you wish to process by passing in an image of that "
"person. Should be a front portrait with a single person in the image. "
"Multiple images can be added space separated. NB: Using face filter will "
"significantly decrease extraction speed and its accuracy cannot be "
"guaranteed."
msgstr ""
"선택적으로 해당 사용자의 이미지를 전달하여 처리할 사용자를 선택합니다. 이미지"
"에 한 사람이 있는 정면 초상화여야 합니다. 여러 이미지를 공백으로 구분하여 추"
"가할 수 있습니다. 주의: 얼굴 필터를 사용하면 추출 속도가 현저히 감소하므로 정"
"확성을 보장할 수 없습니다."

#: lib/cli/args_extract_convert.py:663
msgid ""
"For use with the optional nfilter/filter files. Threshold for positive face "
"recognition. Lower values are stricter. NB: Using face filter will "
"significantly decrease extraction speed and its accuracy cannot be "
"guaranteed."
msgstr ""
"옵션인 nfilter/filter 파일을 함께 사용합니다. 긍정적인 얼굴 인식을 위한 임계"
"값. 낮은 값이 더 엄격합니다. 주의: 얼굴 필터를 사용하면 추출 속도가 현저히 감"
"소하므로 정확성을 보장할 수 없습니다."

#: lib/cli/args_extract_convert.py:676
msgid ""
"The maximum number of parallel processes for performing conversion. "
"Converting images is system RAM heavy so it is possible to run out of memory "
"if you have a lot of processes and not enough RAM to accommodate them all. "
"Setting this to 0 will use the maximum available. No matter what you set "
"this to, it will never attempt to use more processes than are available on "
"your system. If singleprocess is enabled this setting will be ignored."
msgstr ""
"변환을 수행하기 위한 최대 병렬 프로세스 수입니다. 이미지 변환은 시스템 RAM에 "
"부담이 크기 때문에 프로세스가 많고 모든 프로세스를 수용할 RAM이 충분하지 않"
"은 경우 메모리가 부족할 수 있습니다. 이것을 0으로 설정하면 사용 가능한 최대값"
"을 사용합니다. 얼마를 설정하든 시스템에서 사용 가능한 것보다 더 많은 프로세스"
"를 사용하려고 시도하지 않습니다. 단일 프로세스가 활성화된 경우 이 설정은 무시"
"됩니다."

#: lib/cli/args_extract_convert.py:688
msgid ""
"[LEGACY] This only needs to be selected if a legacy model is being loaded or "
"if there are multiple models in the model folder"
msgstr ""
"[LEGACY] 이것은 레거시 모델을 로드 중이거나 모델 폴더에 여러 모델이 있는 경우"
"에만 선택되어야 합니다"

#: lib/cli/args_extract_convert.py:697
msgid ""
"Enable On-The-Fly Conversion. NOT recommended. You should generate a clean "
"alignments file for your destination video. However, if you wish you can "
"generate the alignments on-the-fly by enabling this option. This will use an "
"inferior extraction pipeline and will lead to substandard results. If an "
"alignments file is found, this option will be ignored."
msgstr ""
"실시간 변환을 활성화합니다. 권장하지 않습니다. 당신은 변환 비디오에 대한 깨끗"
"한 alignments 파일을 생성해야 합니다. 그러나 원하는 경우 이 옵션을 활성화하"
"여 즉시 alignments 파일을 생성할 수 있습니다. 이것은 안좋은 추출 과정을 사용"
"하고 표준 이하의 결과로 이어질 것입니다. alignments 파일이 발견되면 이 옵션"
"은 무시됩니다."

#: lib/cli/args_extract_convert.py:709
msgid ""
"When used with --frame-ranges outputs the unchanged frames that are not "
"processed instead of discarding them."
msgstr ""
"사용시 --frame-ranges 인자를 사용하면 변경되지 않은 프레임을 버리지 않은 결과"
"가 출력됩니다."

#: lib/cli/args_extract_convert.py:717
msgid "Swap the model. Instead converting from of A -> B, converts B -> A"
msgstr "모델을 바꿉니다. A -> B에서 변환하는 대신 B -> A로 변환"

#: lib/cli/args_extract_convert.py:723
msgid "Disable multiprocessing. Slower but less resource intensive."
msgstr "멀티프로세싱을 쓰지 않습니다. 느리지만 자원을 덜 소모합니다."
