# SOME DESCRIPTIVE TITLE.
# Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-25 16:09+0100\n"
"PO-Revision-Date: 2023-09-25 16:15+0100\n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: ko_KR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Poedit 3.3.2\n"

#: lib/cli/args.py:192 lib/cli/args.py:202 lib/cli/args.py:210
#: lib/cli/args.py:220
msgid "Global Options"
msgstr "전역 옵션들"

#: lib/cli/args.py:193
msgid ""
"R|Exclude GPUs from use by Faceswap. Select the number(s) which correspond "
"to any GPU(s) that you do not wish to be made available to Faceswap. "
"Selecting all GPUs here will force Faceswap into CPU mode.\n"
"L|{}"
msgstr ""
"R|Faceswap에서 사용되는 GPUs를 제외합니다. Faceswap에서 사용되게 하고 싶지 않"
"은 GPU(s)에 해당하는 번호를 선택하세요. 모든 GPUs를 선택하면 Faceswap으로 하"
"여금 CPU mode를 강제로 사용하게 합니다.\n"
"L|{}"

#: lib/cli/args.py:203
msgid ""
"Optionally overide the saved config with the path to a custom config file."
msgstr "선택적으로 저장된 설정을 경로와 함께 개인 설정 파일에 덮어씌웁니다."

#: lib/cli/args.py:211
msgid ""
"Log level. Stick with INFO or VERBOSE unless you need to file an error "
"report. Be careful with TRACE as it will generate a lot of data"
msgstr ""
"로그 레벨. 오류 리포트가 필요하지 않다면 INFO와 VERBOSE를 사용하세요. 단, 굉"
"장히 많은 데이터를 생성할 수 있는 TRACE는 조심하세요"

#: lib/cli/args.py:221
msgid "Path to store the logfile. Leave blank to store in the faceswap folder"
msgstr "로그파일을 저장할 경로. faceswap 폴더에 저장하고 싶으면 비워두세요"

#: lib/cli/args.py:319 lib/cli/args.py:328 lib/cli/args.py:336
#: lib/cli/args.py:385 lib/cli/args.py:676 lib/cli/args.py:685
msgid "Data"
msgstr "데이터"

#: lib/cli/args.py:320
msgid ""
"Input directory or video. Either a directory containing the image files you "
"wish to process or path to a video file. NB: This should be the source video/"
"frames NOT the source faces."
msgstr ""
"폴더나 비디오를 입력하세요. 당신이 사용하고 싶은 이미지 파일들을 가진 폴더 또"
"는 비디오 파일의 경로여야 합니다. NB: 이 폴더는 원본 비디오여야 합니다."

#: lib/cli/args.py:329
msgid "Output directory. This is where the converted files will be saved."
msgstr "출력 폴더. 변환된 파일들이 저장될 곳입니다."

#: lib/cli/args.py:337
msgid ""
"Optional path to an alignments file. Leave blank if the alignments file is "
"at the default location."
msgstr ""
"(선택적) alignments 파일의 경로. 비워두면 alignments 파일이 기본 위치에 저장"
"됩니다."

#: lib/cli/args.py:360
msgid ""
"Extract faces from image or video sources.\n"
"Extraction plugins can be configured in the 'Settings' Menu"
msgstr ""
"얼굴들을 이미지 또는 비디오에서 추출합니다.\n"
"추출 플러그인은 '설정' 메뉴에서 설정할 수 있습니다"

#: lib/cli/args.py:386
msgid ""
"R|If selected then the input_dir should be a parent folder containing "
"multiple videos and/or folders of images you wish to extract from. The faces "
"will be output to separate sub-folders in the output_dir."
msgstr ""
"R|만약 선택된다면 input_dir은 당신이 추출하고자 하는 여러개의 비디오 그리고/"
"또는 이미지들을 가진 부모 폴더가 되야 합니다. 얼굴들은 output_dir에 분리된 하"
"위 폴더에 저장됩니다."

#: lib/cli/args.py:395 lib/cli/args.py:411 lib/cli/args.py:423
#: lib/cli/args.py:462 lib/cli/args.py:480 lib/cli/args.py:492
#: lib/cli/args.py:501 lib/cli/args.py:510 lib/cli/args.py:695
#: lib/cli/args.py:722 lib/cli/args.py:760
msgid "Plugins"
msgstr "플러그인들"

#: lib/cli/args.py:396
msgid ""
"R|Detector to use. Some of these have configurable settings in '/config/"
"extract.ini' or 'Settings > Configure Extract 'Plugins':\n"
"L|cv2-dnn: A CPU only extractor which is the least reliable and least "
"resource intensive. Use this if not using a GPU and time is important.\n"
"L|mtcnn: Good detector. Fast on CPU, faster on GPU. Uses fewer resources "
"than other GPU detectors but can often return more false positives.\n"
"L|s3fd: Best detector. Slow on CPU, faster on GPU. Can detect more faces and "
"fewer false positives than other GPU detectors, but is a lot more resource "
"intensive."
msgstr ""
"R|사용할 감지기. 몇몇 감지기들은 '/config/extract.ini' 또는 '설정 > 추출 플러"
"그인 설정'에서 설정이 가능합니다:\n"
"L|cv2-dnn: 가장 믿을 수 없고 가장 자원을 덜 사용하며 CPU만을 사용하는 추출기"
"입니다. 만약 GPU를 사용하지 않고 시간이 중요하다면 사용하세요.\n"
"L|mtcnn: 좋은 감지기. CPU에서도 빠르고 GPU에서도 빠릅니다. 다른 GPU 감지기들"
"보다 더 적은 자원을 사용하지만 가끔 더 많은 false positives를 돌려줄 수 있습"
"니다.\n"
"L|s3fd: 가장 좋은 감지기. CPU에선 느리고 GPU에선 빠릅니다. 다른 GPU 감지기들"
"보다 더 많은 얼굴들을 감지할 수 있고 과 더 적은 false positives를 돌려주지만 "
"자원을 굉장히 많이 사용합니다."

#: lib/cli/args.py:412
msgid ""
"R|Aligner to use.\n"
"L|cv2-dnn: A CPU only landmark detector. Faster, less resource intensive, "
"but less accurate. Only use this if not using a GPU and time is important.\n"
"L|fan: Best aligner. Fast on GPU, slow on CPU."
msgstr ""
"R|사용할 Aligner.\n"
"L|cv2-dnn: CPU만을 사용하는 특징점 감지기. 빠르고 자원을 덜 사용하지만 부정확"
"합니다. GPU를 사용하지 않고 시간이 중요할 때에만 사용하세요.\n"
"L|fan: 가장 좋은 aligner. GPU에선 빠르고 CPU에선 느립니다."

#: lib/cli/args.py:424
msgid ""
"R|Additional Masker(s) to use. The masks generated here will all take up GPU "
"RAM. You can select none, one or multiple masks, but the extraction may take "
"longer the more you select. NB: The Extended and Components (landmark based) "
"masks are automatically generated on extraction.\n"
"L|bisenet-fp: Relatively lightweight NN based mask that provides more "
"refined control over the area to be masked including full head masking "
"(configurable in mask settings).\n"
"L|custom: A dummy mask that fills the mask area with all 1s or 0s "
"(configurable in settings). This is only required if you intend to manually "
"edit the custom masks yourself in the manual tool. This mask does not use "
"the GPU so will not use any additional VRAM.\n"
"L|vgg-clear: Mask designed to provide smart segmentation of mostly frontal "
"faces clear of obstructions. Profile faces and obstructions may result in "
"sub-par performance.\n"
"L|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
"frontal faces. The mask model has been specifically trained to recognize "
"some facial obstructions (hands and eyeglasses). Profile faces may result in "
"sub-par performance.\n"
"L|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
"faces. The mask model has been trained by community members and will need "
"testing for further description. Profile faces may result in sub-par "
"performance.\n"
"The auto generated masks are as follows:\n"
"L|components: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks to create a mask.\n"
"L|extended: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks and the mask is extended upwards onto the "
"forehead.\n"
"(eg: `-M unet-dfl vgg-clear`, `--masker vgg-obstructed`)"
msgstr ""
"R|사용할 추가 Mask입니다. 여기서 생성된 마스크는 모두 GPU RAM을 차지합니다. "
"마스크를 0개, 1개 또는 여러 개 선택할 수 있지만 더 많이 선택할수록 추출에 시"
"간이 더 걸릴 수 있습니다. NB: 확장 및 구성 요소(특징점 기반) 마스크는 추출 "
"시 자동으로 생성됩니다.\n"
"L|bisnet-fp: 전체 헤드 마스킹(마스크 설정에서 구성 가능)을 포함하여 마스킹할 "
"영역에 대한 보다 정교한 제어를 제공하는 비교적 가벼운 NN 기반 마스크입니다.\n"
"L|custom: 마스크 영역을 모든 1 또는 0으로 채우는 dummy 마스크입니다(설정에서 "
"구성 가능). 수동 도구에서 사용자 정의 마스크를 직접 수동으로 편집하려는 경우"
"에만 필요합니다. 이 마스크는 GPU를 사용하지 않으므로 추가 VRAM을 사용하지 않"
"습니다.\n"
"L|vgg-clear: 대부분의 정면에 장애물이 없는 스마트한 분할을 제공하도록 설계된 "
"마스크입니다. 프로필 얼굴들 및 장애물들로 인해 성능이 저하될 수 있습니다.\n"
"L|vgg-obstructed: 대부분의 정면 얼굴을 스마트하게 분할할 수 있도록 설계된 마"
"스크입니다. 마스크 모델은 일부 안면 장애물(손과 안경)을 인식하도록 특별히 훈"
"련되었습니다. 프로필 얼굴들은 평균 이하의 성능을 초래할 수 있습니다.\n"
"L|unet-dfl: 대부분 정면 얼굴을 스마트하게 분할하도록 설계된 마스크. 마스크 모"
"델은 커뮤니티 구성원들에 의해 훈련되었으며 추가 설명을 위해 테스트가 필요하"
"다. 프로필 얼굴들은 평균 이하의 성능을 초래할 수 있습니다.\n"
"자동 생성 마스크는 다음과 같습니다.\n"
"L|components: 특징점 위치의 위치를 기반으로 얼굴 분할을 제공하도록 설계된 마"
"스크입니다. 특징점의 외부에는 마스크를 만들기 위해 convex hull가 형성되어 있"
"습니다.\n"
"L|extended: 특징점 위치의 위치를 기반으로 얼굴 분할을 제공하도록 설계된 마스"
"크입니다. 특징점의 외부에는 convex hull가 형성되어 있으며, 마스크는 이마 위"
"로 뻗어 있습ㄴ다.\n"
"(예: '-M unet-dfl vgg-clear', '--masker vgg-obstructed')"

#: lib/cli/args.py:463
msgid ""
"R|Performing normalization can help the aligner better align faces with "
"difficult lighting conditions at an extraction speed cost. Different methods "
"will yield different results on different sets. NB: This does not impact the "
"output face, just the input to the aligner.\n"
"L|none: Don't perform normalization on the face.\n"
"L|clahe: Perform Contrast Limited Adaptive Histogram Equalization on the "
"face.\n"
"L|hist: Equalize the histograms on the RGB channels.\n"
"L|mean: Normalize the face colors to the mean."
msgstr ""
"R|정규화를 수행하면 aligner가 추출 속도 비용으로 어려운 조명 조건의 얼굴을 "
"더 잘 정렬할 수 있습니다. 방법이 다르면 세트마다 결과가 다릅니다. NB: 출력 얼"
"굴에는 영향을 주지 않으며 aligner에 대한 입력에만 영향을 줍니다.\n"
"L|none: 얼굴에 정규화를 수행하지 마십시오.\n"
"L|clahe: 얼굴에 Contrast Limited Adaptive Histogram Equalization를 수행합니"
"다.\n"
"L|hist: RGB 채널의 히스토그램을 동일하게 합니다.\n"
"L|mean: 얼굴 색상을 평균으로 정규화합니다."

#: lib/cli/args.py:481
msgid ""
"The number of times to re-feed the detected face into the aligner. Each time "
"the face is re-fed into the aligner the bounding box is adjusted by a small "
"amount. The final landmarks are then averaged from each iteration. Helps to "
"remove 'micro-jitter' but at the cost of slower extraction speed. The more "
"times the face is re-fed into the aligner, the less micro-jitter should "
"occur but the longer extraction will take."
msgstr ""
"검출된 얼굴을 aligner에 다시 공급하는 횟수입니다. 얼굴이 aligner에 다시 공급"
"될 때마다 경계 상자가 소량 조정됩니다. 그런 다음 각 반복에서 최종 특징점의 평"
"균을 구한다. 'micro-jitter'를 제거하는 데 도움이 되지만 추출 속도가 느려집니"
"다. 얼굴이 aligner에 다시 공급되는 횟수가 많을수록 micro-jitter 적게 발생하지"
"만 추출에 더 오랜 시간이 걸립니다."

#: lib/cli/args.py:493
msgid ""
"Re-feed the initially found aligned face through the aligner. Can help "
"produce better alignments for faces that are rotated beyond 45 degrees in "
"the frame or are at extreme angles. Slows down extraction."
msgstr ""
"_aligner를 통해 처음 발견된 정렬된 얼굴을 재공급합니다. 프레임에서 45도 이상 "
"회전하거나 극단적인 각도에 있는 얼굴을 더 잘 정렬할 수 있습니다. 추출 속도가 "
"느려집니다."

#: lib/cli/args.py:502
msgid ""
"If a face isn't found, rotate the images to try to find a face. Can find "
"more faces at the cost of extraction speed. Pass in a single number to use "
"increments of that size up to 360, or pass in a list of numbers to enumerate "
"exactly what angles to check."
msgstr ""
"얼굴이 발견되지 않으면 이미지를 회전하여 얼굴을 찾습니다. 추출 속도를 희생하"
"면서 더 많은 얼굴을 찾을 수 있습니다. 단일 숫자를 입력하여 해당 크기의 증분"
"을 360까지 사용하거나 숫자 목록을 입력하여 확인할 각도를 정확하게 열거합니다."

#: lib/cli/args.py:511
msgid ""
"Obtain and store face identity encodings from VGGFace2. Slows down extract a "
"little, but will save time if using 'sort by face'"
msgstr ""
"VGGFace2에서 얼굴 식별 인코딩을 가져와 저장합니다. 추출 속도를 약간 늦추지만 "
"'얼굴별로 정렬'을 사용하면 시간을 절약할 수 있습니다."

#: lib/cli/args.py:521 lib/cli/args.py:531 lib/cli/args.py:543
#: lib/cli/args.py:556 lib/cli/args.py:804 lib/cli/args.py:812
#: lib/cli/args.py:826 lib/cli/args.py:839 lib/cli/args.py:853
msgid "Face Processing"
msgstr "얼굴 처리"

#: lib/cli/args.py:522
msgid ""
"Filters out faces detected below this size. Length, in pixels across the "
"diagonal of the bounding box. Set to 0 for off"
msgstr ""
"이 크기 미만으로 탐지된 얼굴을 필터링합니다. 길이, 경계 상자의 대각선에 걸친 "
"픽셀 단위입니다. 0으로 설정하면 꺼집니다"

#: lib/cli/args.py:532
msgid ""
"Optionally filter out people who you do not wish to extract by passing in "
"images of those people. Should be a small variety of images at different "
"angles and in different conditions. A folder containing the required images "
"or multiple image files, space separated, can be selected."
msgstr ""
"선택적으로 추출하지 않을 사람의 이미지들을 전달하여 그 사람들을 제외합니다. "
"각도와 조건이 다른 작은 다양한 이미지여야 합니다. 추출되지 않는데 필요한 이미"
"지들 또는 공백으로 구분된 여러 이미지 파일이 들어 있는 폴더를 선택할 수 있습"
"니다."

#: lib/cli/args.py:544
msgid ""
"Optionally select people you wish to extract by passing in images of that "
"person. Should be a small variety of images at different angles and in "
"different conditions A folder containing the required images or multiple "
"image files, space separated, can be selected."
msgstr ""
"선택적으로 추출하고 싶은 사람의 이미지를 전달하여 그 사람을 선택합니다. 각도"
"와 조건이 다른 작은 다양한 이미지여야 합니다. 추출할 때 필요한 이미지들 또는 "
"공백으로 구분된 여러 이미지 파일이 들어 있는 폴더를 선택할 수 있습니다."

#: lib/cli/args.py:557
msgid ""
"For use with the optional nfilter/filter files. Threshold for positive face "
"recognition. Higher values are stricter."
msgstr ""
"옵션인 nfilter/filter 파일과 함께 사용합니다. 긍정적인 얼굴 인식을 위한 임계"
"값. 값이 높을수록 엄격합니다."

#: lib/cli/args.py:566 lib/cli/args.py:578 lib/cli/args.py:590
#: lib/cli/args.py:602
msgid "output"
msgstr "출력"

#: lib/cli/args.py:567
msgid ""
"The output size of extracted faces. Make sure that the model you intend to "
"train supports your required size. This will only need to be changed for hi-"
"res models."
msgstr ""
"추출된 얼굴의 출력 크기입니다. 훈련하려는 모델이 필요한 크기를 지원하는지 꼭 "
"확인하세요. 이것은 고해상도 모델에 대해서만 변경하면 됩니다."

#: lib/cli/args.py:579
msgid ""
"Extract every 'nth' frame. This option will skip frames when extracting "
"faces. For example a value of 1 will extract faces from every frame, a value "
"of 10 will extract faces from every 10th frame."
msgstr ""
"모든 'n번째' 프레임을 추출합니다. 이 옵션은 얼굴을 추출할 때 건너뛸 프레임을 "
"설정합니다. 예를 들어, 값이 1이면 모든 프레임에서 얼굴이 추출되고, 값이 10이"
"면 모든 10번째 프레임에서 얼굴이 추출됩니다."

#: lib/cli/args.py:591
msgid ""
"Automatically save the alignments file after a set amount of frames. By "
"default the alignments file is only saved at the end of the extraction "
"process. NB: If extracting in 2 passes then the alignments file will only "
"start to be saved out during the second pass. WARNING: Don't interrupt the "
"script when writing the file because it might get corrupted. Set to 0 to "
"turn off"
msgstr ""
"프레임 수가 설정된 후 alignments 파일을 자동으로 저장합니다. 기본적으로 "
"alignments 파일은 추출 프로세스가 끝날 때만 저장됩니다. NB: 2번째 추출에서 성"
"공하면 두 번째 추출 중에만 alignments 파일이 저장되기 시작합니다. 경고: 파일"
"을 쓸 때 스크립트가 손상될 수 있으므로 스크립트를 중단하지 마십시오. 해제하려"
"면 0으로 설정"

#: lib/cli/args.py:603
msgid "Draw landmarks on the ouput faces for debugging purposes."
msgstr "디버깅을 위해 출력 얼굴에 특징점을 그립니다."

#: lib/cli/args.py:609 lib/cli/args.py:618 lib/cli/args.py:626
#: lib/cli/args.py:633 lib/cli/args.py:866 lib/cli/args.py:877
#: lib/cli/args.py:885 lib/cli/args.py:904 lib/cli/args.py:910
msgid "settings"
msgstr "설정"

#: lib/cli/args.py:610
msgid ""
"Don't run extraction in parallel. Will run each part of the extraction "
"process separately (one after the other) rather than all at the same time. "
"Useful if VRAM is at a premium."
msgstr ""
"추출을 병렬로 실행하지 마십시오. 추출 프로세스의 각 부분을 동시에 모두 실행하"
"는 것이 아니라 개별적으로(하나씩) 실행합니다. VRAM이 프리미엄인 경우 유용합니"
"다."

#: lib/cli/args.py:619
msgid ""
"Skips frames that have already been extracted and exist in the alignments "
"file"
msgstr "이미 추출되었거나 alignments 파일에 존재하는 프레임들을 스킵합니다"

#: lib/cli/args.py:627
msgid "Skip frames that already have detected faces in the alignments file"
msgstr "이미 얼굴을 탐지하여 alignments 파일에 존재하는 프레임들을 스킵합니다"

#: lib/cli/args.py:634
msgid "Skip saving the detected faces to disk. Just create an alignments file"
msgstr ""
"탐지된 얼굴을 디스크에 저장하지 않습니다. 그저 alignments 파일을 만듭니다"

#: lib/cli/args.py:656
msgid ""
"Swap the original faces in a source video/images to your final faces.\n"
"Conversion plugins can be configured in the 'Settings' Menu"
msgstr ""
"원본 비디오/이미지의 원래 얼굴을 최종 얼굴으로 바꿉니다.\n"
"변환 플러그인은 '설정' 메뉴에서 구성할 수 있습니다"

#: lib/cli/args.py:677
msgid ""
"Only required if converting from images to video. Provide The original video "
"that the source frames were extracted from (for extracting the fps and "
"audio)."
msgstr ""
"이미지에서 비디오로 변환하는 경우에만 필요합니다. 소스 프레임이 추출된 원본 "
"비디오(fps 및 오디오 추출용)를 입력하세요."

#: lib/cli/args.py:686
msgid ""
"Model directory. The directory containing the trained model you wish to use "
"for conversion."
msgstr ""
"모델 폴더. 당신이 변환에 사용하고자 하는 훈련된 모델을 가진 폴더입니다."

#: lib/cli/args.py:696
msgid ""
"R|Performs color adjustment to the swapped face. Some of these options have "
"configurable settings in '/config/convert.ini' or 'Settings > Configure "
"Convert Plugins':\n"
"L|avg-color: Adjust the mean of each color channel in the swapped "
"reconstruction to equal the mean of the masked area in the original image.\n"
"L|color-transfer: Transfers the color distribution from the source to the "
"target image using the mean and standard deviations of the L*a*b* color "
"space.\n"
"L|manual-balance: Manually adjust the balance of the image in a variety of "
"color spaces. Best used with the Preview tool to set correct values.\n"
"L|match-hist: Adjust the histogram of each color channel in the swapped "
"reconstruction to equal the histogram of the masked area in the original "
"image.\n"
"L|seamless-clone: Use cv2's seamless clone function to remove extreme "
"gradients at the mask seam by smoothing colors. Generally does not give very "
"satisfactory results.\n"
"L|none: Don't perform color adjustment."
msgstr ""
"R|스왑된 얼굴의 색상 조정을 수행합니다. 이러한 옵션 중 일부에는 '/config/"
"convert.ini' 또는 '설정 > 변환 플러그인 구성'에서 구성 가능한 설정이 있습니"
"다.\n"
"L|avg-color: 스왑된 재구성에서 각 색상 채널의 평균이 원본 영상에서 마스킹된 "
"영역의 평균과 동일하도록 조정합니다.\n"
"L|color-transfer: L*a*b* 색 공간의 평균 및 표준 편차를 사용하여 소스에서 대"
"상 이미지로 색 분포를 전송합니다.\n"
"L|manual-balance: 다양한 색 공간에서 이미지의 밸런스를 수동으로 조정합니다. "
"올바른 값을 설정하려면 미리 보기 도구와 함께 사용하는 것이 좋습니다.\n"
"L|match-hist: 스왑된 재구성에서 각 색상 채널의 히스토그램을 조정하여 원래 영"
"상에서 마스킹된 영역의 히스토그램과 동일하게 만듭니다.\n"
"L|seamless-clone: cv2의 원활한 복제 기능을 사용하여 색상을 평활화하여 마스크 "
"심에서 극단적인 gradients을 제거합니다. 일반적으로 매우 만족스러운 결과를 제"
"공하지 않습니다.\n"
"L|none: 색상 조정을 수행하지 않습니다."

#: lib/cli/args.py:723
msgid ""
"R|Masker to use. NB: The mask you require must exist within the alignments "
"file. You can add additional masks with the Mask Tool.\n"
"L|none: Don't use a mask.\n"
"L|bisenet-fp_face: Relatively lightweight NN based mask that provides more "
"refined control over the area to be masked (configurable in mask settings). "
"Use this version of bisenet-fp if your model is trained with 'face' or "
"'legacy' centering.\n"
"L|bisenet-fp_head: Relatively lightweight NN based mask that provides more "
"refined control over the area to be masked (configurable in mask settings). "
"Use this version of bisenet-fp if your model is trained with 'head' "
"centering.\n"
"L|custom_face: Custom user created, face centered mask.\n"
"L|custom_head: Custom user created, head centered mask.\n"
"L|components: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks to create a mask.\n"
"L|extended: Mask designed to provide facial segmentation based on the "
"positioning of landmark locations. A convex hull is constructed around the "
"exterior of the landmarks and the mask is extended upwards onto the "
"forehead.\n"
"L|vgg-clear: Mask designed to provide smart segmentation of mostly frontal "
"faces clear of obstructions. Profile faces and obstructions may result in "
"sub-par performance.\n"
"L|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
"frontal faces. The mask model has been specifically trained to recognize "
"some facial obstructions (hands and eyeglasses). Profile faces may result in "
"sub-par performance.\n"
"L|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
"faces. The mask model has been trained by community members and will need "
"testing for further description. Profile faces may result in sub-par "
"performance.\n"
"L|predicted: If the 'Learn Mask' option was enabled during training, this "
"will use the mask that was created by the trained model."
msgstr ""
"R|사용할 마스크. NB: 필요한 마스크는 alignments 파일 내에 있어야 합니다. 마스"
"크 도구를 사용하여 마스크를 추가할 수 있습니다.\n"
"L|none: 마스크 쓰지 마세요.\n"
"L|bisnet-fp_face: 마스크할 영역을 보다 정교하게 제어할 수 있는 비교적 가벼운 "
"NN 기반 마스크입니다(마스크 설정에서 구성 가능). 모델이 '얼굴' 또는 '레거시' "
"중심으로 훈련된 경우 이 버전의 bisnet-fp를 사용하십시오.\n"
"L|bisnet-fp_head: 마스크할 영역을 보다 정교하게 제어할 수 있는 비교적 가벼운 "
"NN 기반 마스크입니다(마스크 설정에서 구성 가능). 모델이 '헤드' 중심으로 훈련"
"된 경우 이 버전의 bisnet-fp를 사용하십시오.\n"
"L|custom_face: 사용자 지정 사용자가 생성한 얼굴 중심 마스크입니다.\n"
"L|custom_head: 사용자 지정 사용자가 생성한 머리 중심 마스크입니다.\n"
"L|components: 특징점 위치의 배치를 기반으로 얼굴 분할을 제공하도록 설계된 마"
"스크입니다. 특징점의 외부에는 마스크를 만들기 위해 convex hull가 형성되어 있"
"습니다.\n"
"L|extended: 특징점 위치의 배치를 기반으로 얼굴 분할을 제공하도록 설계된 마스"
"크입니다. 지형지물의 외부에는 convex hull가 형성되어 있으며, 마스크는 이마 위"
"로 뻗어 있습니다.\n"
"L|vgg-clear: 대부분의 정면에 장애물이 없는 스마트한 분할을 제공하도록 설계된 "
"마스크입니다. 옆 얼굴 및 장애물로 인해 성능이 저하될 수 있습니다.\n"
"L|vgg-obstructed: 대부분의 정면 얼굴을 스마트하게 분할할 수 있도록 설계된 마"
"스크입니다. 마스크 모델은 일부 안면 장애물(손과 안경)을 인식하도록 특별히 훈"
"련되었습니다. 옆 얼굴은 평균 이하의 성능을 초래할 수 있습니다.\n"
"L|unet-dfl: 대부분 정면 얼굴을 스마트하게 분할하도록 설계된 마스크. 마스크 모"
"델은 커뮤니티 구성원들에 의해 훈련되었으며 추가 설명을 위해 테스트가 필요하"
"다. 옆 얼굴은 평균 이하의 성능을 초래할 수 있습니다.\n"
"L|predicted: 교육 중에 'Learn Mask(마스크 학습)' 옵션이 활성화된 경우에는 교"
"육을 받은 모델이 만든 마스크가 사용됩니다."

#: lib/cli/args.py:761
msgid ""
"R|The plugin to use to output the converted images. The writers are "
"configurable in '/config/convert.ini' or 'Settings > Configure Convert "
"Plugins:'\n"
"L|ffmpeg: [video] Writes out the convert straight to video. When the input "
"is a series of images then the '-ref' (--reference-video) parameter must be "
"set.\n"
"L|gif: [animated image] Create an animated gif.\n"
"L|opencv: [images] The fastest image writer, but less options and formats "
"than other plugins.\n"
"L|patch: [images] Outputs the raw swapped face patch, along with the "
"transformation matrix required to re-insert the face back into the original "
"frame. Use this option if you wish to post-process and composite the final "
"face within external tools.\n"
"L|pillow: [images] Slower than opencv, but has more options and supports "
"more formats."
msgstr ""
"R|변환된 이미지를 출력하는 데 사용할 플러그인입니다. 기록 장치는 '/config/"
"convert.ini' 또는 '설정 > 변환 플러그인 구성:'에서 구성할 수 있습니다.\n"
"L|ffmpeg: [video] 변환된 결과를 바로 video로 씁니다. 입력이 영상 시리즈인 경"
"우 '-ref'(--reference-video) 파라미터를 설정해야 합니다.\n"
"L|gif : [애니메이션 이미지] 애니메이션 gif를 만듭니다.\n"
"L|opencv: [이미지] 가장 빠른 이미지 작성기이지만 다른 플러그인에 비해 옵션과 "
"형식이 적습니다.\n"
"L|patch: [이미지] 원래 프레임에 얼굴을 다시 삽입하는 데 필요한 변환 행렬과 함"
"께 원시 교체된 얼굴 패치를 출력합니다.\n"
"L|pillow: [images] opencv보다 느리지만 더 많은 옵션이 있고 더 많은 형식을 지"
"원합니다."

#: lib/cli/args.py:784 lib/cli/args.py:791 lib/cli/args.py:896
msgid "Frame Processing"
msgstr "프레임 처리"

#: lib/cli/args.py:785
#, python-format
msgid ""
"Scale the final output frames by this amount. 100%% will output the frames "
"at source dimensions. 50%% at half size 200%% at double size"
msgstr ""
"최종 출력 프레임의 크기를 이 양만큼 조정합니다. 100%%는 원본의 차원에서 프레"
"임을 출력합니다. 50%%는 절반 크기에서, 200%%는 두 배 크기에서"

#: lib/cli/args.py:792
msgid ""
"Frame ranges to apply transfer to e.g. For frames 10 to 50 and 90 to 100 use "
"--frame-ranges 10-50 90-100. Frames falling outside of the selected range "
"will be discarded unless '-k' (--keep-unchanged) is selected. NB: If you are "
"converting from images, then the filenames must end with the frame-number!"
msgstr ""
"예를 들어 전송을 적용할 프레임 범위 프레임 10 - 50 및 90 - 100의 경우 --"
"frame-ranges 10-50 90-100을 사용합니다. '-k'(--keep-unchanged)를 선택하지 않"
"으면 선택한 범위를 벗어나는 프레임이 삭제됩니다. NB: 이미지에서 변환하는 경"
"우 파일 이름은 프레임 번호로 끝나야 합니다!"

#: lib/cli/args.py:805
msgid ""
"Scale the swapped face by this percentage. Positive values will enlarge the "
"face, Negative values will shrink the face."
msgstr ""
"이 백분율로 교체된 면의 크기를 조정합니다. 양수 값은 얼굴을 확대하고, 음수 값"
"은 얼굴을 축소합니다."

#: lib/cli/args.py:813
msgid ""
"If you have not cleansed your alignments file, then you can filter out faces "
"by defining a folder here that contains the faces extracted from your input "
"files/video. If this folder is defined, then only faces that exist within "
"your alignments file and also exist within the specified folder will be "
"converted. Leaving this blank will convert all faces that exist within the "
"alignments file."
msgstr ""
"만약 alignments 파일을 지우지 않은 경우 입력 파일/비디오에서 추출된 얼굴이 포"
"함된 폴더를 정의하여 얼굴을 걸러낼 수 있습니다. 이 폴더가 정의된 경우 "
"alignments 파일 내에 존재하거나 지정된 폴더 내에 존재하는 얼굴만 변환됩니다. "
"이 항목을 공백으로 두면 alignments 파일 내에 있는 모든 얼굴이 변환됩니다."

#: lib/cli/args.py:827
msgid ""
"Optionally filter out people who you do not wish to process by passing in an "
"image of that person. Should be a front portrait with a single person in the "
"image. Multiple images can be added space separated. NB: Using face filter "
"will significantly decrease extraction speed and its accuracy cannot be "
"guaranteed."
msgstr ""
"선택적으로 처리하고 싶지 않은 사람의 이미지를 전달하여 그 사람을 걸러낼 수 있"
"습니다. 이미지는 한 사람의 정면 모습이여야 합니다. 여러 이미지를 공백으로 구"
"분하여 추가할 수 있습니다. 주의: 얼굴 필터를 사용하면 추출 속도가 현저히 감소"
"하므로 정확성을 보장할 수 없습니다."

#: lib/cli/args.py:840
msgid ""
"Optionally select people you wish to process by passing in an image of that "
"person. Should be a front portrait with a single person in the image. "
"Multiple images can be added space separated. NB: Using face filter will "
"significantly decrease extraction speed and its accuracy cannot be "
"guaranteed."
msgstr ""
"선택적으로 해당 사용자의 이미지를 전달하여 처리할 사용자를 선택합니다. 이미지"
"에 한 사람이 있는 정면 초상화여야 합니다. 여러 이미지를 공백으로 구분하여 추"
"가할 수 있습니다. 주의: 얼굴 필터를 사용하면 추출 속도가 현저히 감소하므로 정"
"확성을 보장할 수 없습니다."

#: lib/cli/args.py:854
msgid ""
"For use with the optional nfilter/filter files. Threshold for positive face "
"recognition. Lower values are stricter. NB: Using face filter will "
"significantly decrease extraction speed and its accuracy cannot be "
"guaranteed."
msgstr ""
"옵션인 nfilter/filter 파일을 함께 사용합니다. 긍정적인 얼굴 인식을 위한 임계"
"값. 낮은 값이 더 엄격합니다. 주의: 얼굴 필터를 사용하면 추출 속도가 현저히 감"
"소하므로 정확성을 보장할 수 없습니다."

#: lib/cli/args.py:867
msgid ""
"The maximum number of parallel processes for performing conversion. "
"Converting images is system RAM heavy so it is possible to run out of memory "
"if you have a lot of processes and not enough RAM to accommodate them all. "
"Setting this to 0 will use the maximum available. No matter what you set "
"this to, it will never attempt to use more processes than are available on "
"your system. If singleprocess is enabled this setting will be ignored."
msgstr ""
"변환을 수행하기 위한 최대 병렬 프로세스 수입니다. 이미지 변환은 시스템 RAM에 "
"부담이 크기 때문에 프로세스가 많고 모든 프로세스를 수용할 RAM이 충분하지 않"
"은 경우 메모리가 부족할 수 있습니다. 이것을 0으로 설정하면 사용 가능한 최대값"
"을 사용합니다. 얼마를 설정하든 시스템에서 사용 가능한 것보다 더 많은 프로세스"
"를 사용하려고 시도하지 않습니다. 단일 프로세스가 활성화된 경우 이 설정은 무시"
"됩니다."

#: lib/cli/args.py:878
msgid ""
"[LEGACY] This only needs to be selected if a legacy model is being loaded or "
"if there are multiple models in the model folder"
msgstr ""
"[LEGACY] 이것은 레거시 모델을 로드 중이거나 모델 폴더에 여러 모델이 있는 경우"
"에만 선택되어야 합니다"

#: lib/cli/args.py:886
msgid ""
"Enable On-The-Fly Conversion. NOT recommended. You should generate a clean "
"alignments file for your destination video. However, if you wish you can "
"generate the alignments on-the-fly by enabling this option. This will use an "
"inferior extraction pipeline and will lead to substandard results. If an "
"alignments file is found, this option will be ignored."
msgstr ""
"실시간 변환을 활성화합니다. 권장하지 않습니다. 당신은 변환 비디오에 대한 깨끗"
"한 alignments 파일을 생성해야 합니다. 그러나 원하는 경우 이 옵션을 활성화하"
"여 즉시 alignments 파일을 생성할 수 있습니다. 이것은 안좋은 추출 과정을 사용"
"하고 표준 이하의 결과로 이어질 것입니다. alignments 파일이 발견되면 이 옵션"
"은 무시됩니다."

#: lib/cli/args.py:897
msgid ""
"When used with --frame-ranges outputs the unchanged frames that are not "
"processed instead of discarding them."
msgstr ""
"사용시 --frame-ranges 인자를 사용하면 변경되지 않은 프레임을 버리지 않은 결과"
"가 출력됩니다."

#: lib/cli/args.py:905
msgid "Swap the model. Instead converting from of A -> B, converts B -> A"
msgstr "모델을 바꿉니다. A -> B에서 변환하는 대신 B -> A로 변환"

#: lib/cli/args.py:911
msgid "Disable multiprocessing. Slower but less resource intensive."
msgstr "멀티프로세싱을 쓰지 않습니다. 느리지만 자원을 덜 소모합니다."

#: lib/cli/args.py:927
msgid ""
"Train a model on extracted original (A) and swap (B) faces.\n"
"Training models can take a long time. Anything from 24hrs to over a week\n"
"Model plugins can be configured in the 'Settings' Menu"
msgstr ""
"추출된 원래(A) 얼굴과 스왑(B) 얼굴에 대한 모델을 훈련합니다.\n"
"모델을 훈련하는 데 시간이 오래 걸릴 수 있습니다. 24시간에서 일주일 이상의 시"
"간이 필요합니다.\n"
"모델 플러그인은 '설정' 메뉴에서 구성할 수 있습니다"

#: lib/cli/args.py:946 lib/cli/args.py:955
msgid "faces"
msgstr "얼굴들"

#: lib/cli/args.py:947
msgid ""
"Input directory. A directory containing training images for face A. This is "
"the original face, i.e. the face that you want to remove and replace with "
"face B."
msgstr ""
"입력 디렉토리. 얼굴 A에 대한 훈련 이미지가 포함된 디렉토리입니다. 이것은 원"
"래 얼굴, 즉 제거하고 B 얼굴로 대체하려는 얼굴입니다."

#: lib/cli/args.py:956
msgid ""
"Input directory. A directory containing training images for face B. This is "
"the swap face, i.e. the face that you want to place onto the head of person "
"A."
msgstr ""
"입력 디렉터리. 얼굴 B에 대한 훈련 이미지를 포함하는 디렉토리. 이것은 대체 얼"
"굴, 즉 사람 A의 얼굴 앞에 배치하려는 얼굴이다."

#: lib/cli/args.py:964 lib/cli/args.py:976 lib/cli/args.py:992
#: lib/cli/args.py:1017 lib/cli/args.py:1027
msgid "model"
msgstr "모델"

#: lib/cli/args.py:965
msgid ""
"Model directory. This is where the training data will be stored. You should "
"always specify a new folder for new models. If starting a new model, select "
"either an empty folder, or a folder which does not exist (which will be "
"created). If continuing to train an existing model, specify the location of "
"the existing model."
msgstr ""
"모델 디렉토리. 여기에 훈련 데이터가 저장됩니다. 새 모델의 경우 항상 새 폴더"
"를 지정해야 합니다. 새 모델을 시작할 경우 빈 폴더 또는 존재하지 않는 폴더(생"
"성될 폴더)를 선택합니다. 기존 모델을 계속 학습하는 경우 기존 모델의 위치를 지"
"정합니다."

#: lib/cli/args.py:977
msgid ""
"R|Load the weights from a pre-existing model into a newly created model. For "
"most models this will load weights from the Encoder of the given model into "
"the encoder of the newly created model. Some plugins may have specific "
"configuration options allowing you to load weights from other layers. "
"Weights will only be loaded when creating a new model. This option will be "
"ignored if you are resuming an existing model. Generally you will also want "
"to 'freeze-weights' whilst the rest of your model catches up with your "
"Encoder.\n"
"NB: Weights can only be loaded from models of the same plugin as you intend "
"to train."
msgstr ""
"R|기존 모델의 가중치를 새로 생성된 모델로 로드합니다. 대부분의 모델에서는 주"
"어진 모델의 인코더에서 새로 생성된 모델의 인코더로 가중치를 로드합니다. 일부 "
"플러그인에는 다른 층에서 가중치를 로드할 수 있는 특정 구성 옵션이 있을 수 있"
"습니다. 가중치는 새 모델을 생성할 때만 로드됩니다. 기존 모델을 재개하는 경우 "
"이 옵션은 무시됩니다. 일반적으로 나머지 모델이 인코더를 따라잡는 동안에도 '가"
"중치 동결'이 필요합니다.\n"
"주의: 가중치는 훈련하려는 플러그인 모델에서만 로드할 수 있습니다."

#: lib/cli/args.py:993
msgid ""
"R|Select which trainer to use. Trainers can be configured from the Settings "
"menu or the config folder.\n"
"L|original: The original model created by /u/deepfakes.\n"
"L|dfaker: 64px in/128px out model from dfaker. Enable 'warp-to-landmarks' "
"for full dfaker method.\n"
"L|dfl-h128: 128px in/out model from deepfacelab\n"
"L|dfl-sae: Adaptable model from deepfacelab\n"
"L|dlight: A lightweight, high resolution DFaker variant.\n"
"L|iae: A model that uses intermediate layers to try to get better details\n"
"L|lightweight: A lightweight model for low-end cards. Don't expect great "
"results. Can train as low as 1.6GB with batch size 8.\n"
"L|realface: A high detail, dual density model based on DFaker, with "
"customizable in/out resolution. The autoencoders are unbalanced so B>A swaps "
"won't work so well. By andenixa et al. Very configurable.\n"
"L|unbalanced: 128px in/out model from andenixa. The autoencoders are "
"unbalanced so B>A swaps won't work so well. Very configurable.\n"
"L|villain: 128px in/out model from villainguy. Very resource hungry (You "
"will require a GPU with a fair amount of VRAM). Good for details, but more "
"susceptible to color differences."
msgstr ""
"R|사용할 훈련 모델을 선택합니다. 훈련 모델은 설정 메뉴 또는 구성 폴더에서 구"
"성할 수 있습니다.\n"
"L|original: /u/deepfakes로 만든 원래 모델입니다.\n"
"L|dfaker: 64px in/128px out 모델 from dfaker. Full dfaker 메서드에 대해 '특징"
"점으로 변환'를 활성화합니다.\n"
"L|dfl-h128: Deepfake lab의 128px in/out 모델\n"
"L|dfl-sae: Deepface Lab의 적응형 모델\n"
"L|dlight: 경량, 고해상도 DFaker 변형입니다.\n"
"L|iae: 중간 층들을 사용하여 더 나은 세부 정보를 얻기 위해 노력하는 모델.\n"
"L|lightweight: 저가형 카드용 경량 모델. 좋은 결과를 기대하지 마세요. 최대한 "
"낮게 잡아서 배치 사이즈 8에 1.6GB까지 훈련이 가능합니다.\n"
"L|realface: DFaker를 기반으로 한 높은 디테일의 이중 밀도 모델로, 사용자 정의 "
"가능한 입/출력 해상도를 제공합니다. 오토인코더가 불균형하여 B>A 스왑이 잘 작"
"동하지 않습니다. Andenixa 등에 의해. 매우 구성 가능합니다.\n"
"L|unbalanced: andenixa의 128px in/out 모델. 오토인코더가 불균형하여 B>A 스왑"
"이 잘 작동하지 않습니다. 매우 구성 가능합니다.\n"
"L|villain : villainguy의 128px in/out 모델. 리소스가 매우 부족합니다( 상당한 "
"양의 VRAM이 있는 GPU가 필요합니다). 세부 사항에는 좋지만 색상 차이에 더 취약"
"합니다."

#: lib/cli/args.py:1018
msgid ""
"Output a summary of the model and exit. If a model folder is provided then a "
"summary of the saved model is displayed. Otherwise a summary of the model "
"that would be created by the chosen plugin and configuration settings is "
"displayed."
msgstr ""
"모델 요약을 출력하고 종료합니다. 모델 폴더가 제공되면 저장된 모델의 요약이 표"
"시됩니다. 그렇지 않으면 선택한 플러그인 및 구성 설정에 의해 생성되는 모델 요"
"약이 표시됩니다."

#: lib/cli/args.py:1028
msgid ""
"Freeze the weights of the model. Freezing weights means that some of the "
"parameters in the model will no longer continue to learn, but those that are "
"not frozen will continue to learn. For most models, this will freeze the "
"encoder, but some models may have configuration options for freezing other "
"layers."
msgstr ""
"모델의 가중치를 동결합니다. 가중치를 고정하면 모델의 일부 매개변수가 더 이상 "
"학습되지 않지만 고정되지 않은 매개변수는 계속 학습됩니다. 대부분의 모델에서 "
"이렇게 하면 인코더가 고정되지만 일부 모델에는 다른 레이어를 고정하기 위한 구"
"성 옵션이 있을 수 있습니다."

#: lib/cli/args.py:1041 lib/cli/args.py:1053 lib/cli/args.py:1067
#: lib/cli/args.py:1082 lib/cli/args.py:1090
msgid "training"
msgstr "훈련"

#: lib/cli/args.py:1042
msgid ""
"Batch size. This is the number of images processed through the model for "
"each side per iteration. NB: As the model is fed 2 sides at a time, the "
"actual number of images within the model at any one time is double the "
"number that you set here. Larger batches require more GPU RAM."
msgstr ""
"배치 크기. 반복당 각 측면에 대해 모델을 통해 처리되는 이미지 수입니다. NB: "
"한 번에 모델에게 2개의 측면이 공급되므로 한 번에 모델 내의 실제 이미지 수는 "
"여기에서 설정한 수의 두 배입니다. 더 큰 배치에는 더 많은 GPU RAM이 필요합니"
"다."

#: lib/cli/args.py:1054
msgid ""
"Length of training in iterations. This is only really used for automation. "
"There is no 'correct' number of iterations a model should be trained for. "
"You should stop training when you are happy with the previews. However, if "
"you want the model to stop automatically at a set number of iterations, you "
"can set that value here."
msgstr ""
"반복에서 훈련 길이. 이것은 실제로 자동화에만 사용됩니다. 모델을 훈련해야 하"
"는 '올바른' 반복 횟수는 없습니다. 미리 보기에 만족하면 훈련을 중단해야 합니"
"다. 그러나 설정된 반복 횟수에서 모델이 자동으로 중지되도록 하려면 여기에서 해"
"당 값을 설정할 수 있습니다."

#: lib/cli/args.py:1068
msgid ""
"R|Select the distribution stategy to use.\n"
"L|default: Use Tensorflow's default distribution strategy.\n"
"L|central-storage: Centralizes variables on the CPU whilst operations are "
"performed on 1 or more local GPUs. This can help save some VRAM at the cost "
"of some speed by not storing variables on the GPU. Note: Mixed-Precision is "
"not supported on multi-GPU setups.\n"
"L|mirrored: Supports synchronous distributed training across multiple local "
"GPUs. A copy of the model and all variables are loaded onto each GPU with "
"batches distributed to each GPU at each iteration."
msgstr ""
"R|사용할 배포 상태를 선택합니다.\n"
"L|default: Tensorflow의 기본 배포 전략을 사용합니다.\n"
"L|central-storage: 작업이 1개 이상의 로컬 GPU에서 수행되는 동안 CPU의 변수를 "
"중앙 집중화합니다. 이렇게 하면 GPU에 변수를 저장하지 않음으로써 약간의 속도"
"를 희생하여 일부 VRAM을 절약할 수 있습니다. 참고: 다중 정밀도는 다중 GPU 설정"
"에서 지원되지 않습니다.\n"
"L|mirrored: 여러 로컬 GPU에서 동기화 분산 훈련을 지원합니다. 모델의 복사본과 "
"모든 변수는 각 반복에서 각 GPU에 배포된 배치들와 함께 각 GPU에 로드됩니다."

#: lib/cli/args.py:1083
msgid ""
"Disables TensorBoard logging. NB: Disabling logs means that you will not be "
"able to use the graph or analysis for this session in the GUI."
msgstr ""
"텐서보드 로깅을 비활성화합니다. 주의: 로그를 비활성화하면 GUI에서 이 세션에 "
"대한 그래프 또는 분석을 사용할 수 없습니다."

#: lib/cli/args.py:1091
msgid ""
"Use the Learning Rate Finder to discover the optimal learning rate for "
"training. For new models, this will calculate the optimal learning rate for "
"the model. For existing models this will use the optimal learning rate that "
"was discovered when initializing the model. Setting this option will ignore "
"the manually configured learning rate (configurable in train settings)."
msgstr ""
"학습률 찾기를 사용하여 훈련을 위한 최적의 학습률을 찾아보세요. 새 모델의 경"
"우 모델에 대한 최적의 학습률을 계산합니다. 기존 모델의 경우 모델을 초기화할 "
"때 발견된 최적의 학습률을 사용합니다. 이 옵션을 설정하면 수동으로 구성된 학습"
"률(기차 설정에서 구성 가능)이 무시됩니다."

#: lib/cli/args.py:1104 lib/cli/args.py:1114
msgid "Saving"
msgstr "저장"

#: lib/cli/args.py:1105
msgid "Sets the number of iterations between each model save."
msgstr "각 모델 저장 사이의 반복 횟수를 설정합니다."

#: lib/cli/args.py:1115
msgid ""
"Sets the number of iterations before saving a backup snapshot of the model "
"in it's current state. Set to 0 for off."
msgstr ""
"현재 상태에서 모델의 백업 스냅샷을 저장하기 전에 반복할 횟수를 설정합니다. 0"
"으로 설정하면 꺼집니다."

#: lib/cli/args.py:1122 lib/cli/args.py:1133 lib/cli/args.py:1144
msgid "timelapse"
msgstr "타임랩스"

#: lib/cli/args.py:1123
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. "
"This should be the input folder of 'A' faces that you would like to use for "
"creating the timelapse. You must also supply a --timelapse-output and a --"
"timelapse-input-B parameter."
msgstr ""
"타임랩스를 만드는 옵션입니다. Timelapse(시간 경과)는 저장을 반복할 때마다 선"
"택한 얼굴의 이미지를 Timelapse-output(시간 경과 출력) 폴더에 저장합니다. 타임"
"랩스를 만드는 데 사용할 'A' 얼굴의 입력 폴더여야 합니다. 또한 사용자는 --"
"timelapse-output 및 --timelapse-input-B 매개 변수를 제공해야 합니다."

#: lib/cli/args.py:1134
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. "
"This should be the input folder of 'B' faces that you would like to use for "
"creating the timelapse. You must also supply a --timelapse-output and a --"
"timelapse-input-A parameter."
msgstr ""
"타임 랩스를 만드는 데 선택적입니다. Timelapse(시간 경과)는 저장을 반복할 때마"
"다 선택한 얼굴의 이미지를 Timelapse-output(시간 경과 출력) 폴더에 저장합니"
"다. 타임 랩스를 만드는 데 사용할 'B' 얼굴의 입력 폴더여야 합니다. 또한 사용자"
"는 --timelapse-output 및 --timelapse-input-A 매개 변수를 제공해야 합니다."

#: lib/cli/args.py:1145
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. If "
"the input folders are supplied but no output folder, it will default to your "
"model folder /timelapse/"
msgstr ""
"타임랩스를 만드는 데 선택적입니다. Timelapse(시간 경과)는 저장을 반복할 때마"
"다 선택한 얼굴의 이미지를 Timelapse-output(시간 경과 출력) 폴더에 저장합니"
"다. 입력 폴더가 제공되었지만 출력 폴더가 없는 경우 모델 폴더에 /timelapse/로 "
"기본 설정됩니다"

#: lib/cli/args.py:1154 lib/cli/args.py:1161
msgid "preview"
msgstr "미리보기"

#: lib/cli/args.py:1155
msgid "Show training preview output. in a separate window."
msgstr "훈련 미리보기 결과를 각기 다른 창에서 보여줍니다."

#: lib/cli/args.py:1162
msgid ""
"Writes the training result to a file. The image will be stored in the root "
"of your FaceSwap folder."
msgstr ""
"훈련 결과를 파일에 씁니다. 이미지는 Faceswap 폴더의 최상위 폴더에 저장됩니다."

#: lib/cli/args.py:1169 lib/cli/args.py:1178 lib/cli/args.py:1187
#: lib/cli/args.py:1196
msgid "augmentation"
msgstr "보정"

#: lib/cli/args.py:1170
msgid ""
"Warps training faces to closely matched Landmarks from the opposite face-set "
"rather than randomly warping the face. This is the 'dfaker' way of doing "
"warping."
msgstr ""
"무작위로 얼굴을 변환하지 않고 반대쪽 얼굴 세트에서 특징점과 밀접하게 일치하도"
"록 훈련 얼굴을 변환해줍니다. 이것은 변환하는 'dfaker' 방식이다."

#: lib/cli/args.py:1179
msgid ""
"To effectively learn, a random set of images are flipped horizontally. "
"Sometimes it is desirable for this not to occur. Generally this should be "
"left off except for during 'fit training'."
msgstr ""
"효과적으로 학습하기 위해 임의의 이미지 세트를 수평으로 뒤집습니다. 때때로 이"
"런 일이 일어나지 않는 것이 바람직합니다. 일반적으로 'fit training' 중을 제외"
"하고는 이 작업을 중단해야 합니다."

#: lib/cli/args.py:1188
msgid ""
"Color augmentation helps make the model less susceptible to color "
"differences between the A and B sets, at an increased training time cost. "
"Enable this option to disable color augmentation."
msgstr ""
"색상 보정은 모델이 A와 B 세트 사이의 색상 차이에 덜 민감하게 만드는 데 도움"
"이 되며, 훈련 시간 비용이 증가합니다. 색상 보저를 사용하지 않으려면 이 옵션"
"을 사용합니다."

#: lib/cli/args.py:1197
msgid ""
"Warping is integral to training the Neural Network. This option should only "
"be enabled towards the very end of training to try to bring out more detail. "
"Think of it as 'fine-tuning'. Enabling this option from the beginning is "
"likely to kill a model and lead to terrible results."
msgstr ""
"변환은 신경망을 훈련하는 데 필수적입니다. 이 옵션은 보다 세부적인 것들을 뽑아"
"내위하여 훈련 막바지까지 활성화하여야 합니다. 이것은 '미세 조정'이라고 생각하"
"면 됩니다. 처음부터 이 옵션을 활성화하면 모델이 죽을 수있고 끔찍한 결과를 초"
"래할 수 있습니다."

#: lib/cli/args.py:1222
msgid "Output to Shell console instead of GUI console"
msgstr "결과를 GUI 콘솔이 아닌 쉘 콘솔에 출력합니다"

#~ msgid ""
#~ "[Deprecated - Use '-D, --distribution-strategy' instead] Use the "
#~ "Tensorflow Mirrored Distrubution Strategy to train on multiple GPUs."
#~ msgstr ""
#~ "[Deprecated - 대신 '-D, --distribution-strategy' 사용] Tensorflow 미러 분"
#~ "산 전략을 사용하여 여러 GPU에서 훈련합니다."
