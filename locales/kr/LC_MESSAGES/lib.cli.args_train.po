# SOME DESCRIPTIVE TITLE.
# Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-03-28 18:04+0000\n"
"PO-Revision-Date: 2024-03-28 18:16+0000\n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: ko_KR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Poedit 3.4.2\n"

#: lib/cli/args_train.py:30
msgid ""
"Train a model on extracted original (A) and swap (B) faces.\n"
"Training models can take a long time. Anything from 24hrs to over a week\n"
"Model plugins can be configured in the 'Settings' Menu"
msgstr ""
"추출된 원래(A) 얼굴과 스왑(B) 얼굴에 대한 모델을 훈련합니다.\n"
"모델을 훈련하는 데 시간이 오래 걸릴 수 있습니다. 24시간에서 일주일 이상의 시"
"간이 필요합니다.\n"
"모델 플러그인은 '설정' 메뉴에서 구성할 수 있습니다"

#: lib/cli/args_train.py:49 lib/cli/args_train.py:58
msgid "faces"
msgstr "얼굴들"

#: lib/cli/args_train.py:51
msgid ""
"Input directory. A directory containing training images for face A. This is "
"the original face, i.e. the face that you want to remove and replace with "
"face B."
msgstr ""
"입력 디렉토리. 얼굴 A에 대한 훈련 이미지가 포함된 디렉토리입니다. 이것은 원"
"래 얼굴, 즉 제거하고 B 얼굴로 대체하려는 얼굴입니다."

#: lib/cli/args_train.py:60
msgid ""
"Input directory. A directory containing training images for face B. This is "
"the swap face, i.e. the face that you want to place onto the head of person "
"A."
msgstr ""
"입력 디렉터리. 얼굴 B에 대한 훈련 이미지를 포함하는 디렉토리. 이것은 대체 얼"
"굴, 즉 사람 A의 얼굴 앞에 배치하려는 얼굴이다."

#: lib/cli/args_train.py:67 lib/cli/args_train.py:80 lib/cli/args_train.py:97
#: lib/cli/args_train.py:123 lib/cli/args_train.py:133
msgid "model"
msgstr "모델"

#: lib/cli/args_train.py:69
msgid ""
"Model directory. This is where the training data will be stored. You should "
"always specify a new folder for new models. If starting a new model, select "
"either an empty folder, or a folder which does not exist (which will be "
"created). If continuing to train an existing model, specify the location of "
"the existing model."
msgstr ""
"모델 디렉토리. 여기에 훈련 데이터가 저장됩니다. 새 모델의 경우 항상 새 폴더"
"를 지정해야 합니다. 새 모델을 시작할 경우 빈 폴더 또는 존재하지 않는 폴더(생"
"성될 폴더)를 선택합니다. 기존 모델을 계속 학습하는 경우 기존 모델의 위치를 지"
"정합니다."

#: lib/cli/args_train.py:82
msgid ""
"R|Load the weights from a pre-existing model into a newly created model. For "
"most models this will load weights from the Encoder of the given model into "
"the encoder of the newly created model. Some plugins may have specific "
"configuration options allowing you to load weights from other layers. "
"Weights will only be loaded when creating a new model. This option will be "
"ignored if you are resuming an existing model. Generally you will also want "
"to 'freeze-weights' whilst the rest of your model catches up with your "
"Encoder.\n"
"NB: Weights can only be loaded from models of the same plugin as you intend "
"to train."
msgstr ""
"R|기존 모델의 가중치를 새로 생성된 모델로 로드합니다. 대부분의 모델에서는 주"
"어진 모델의 인코더에서 새로 생성된 모델의 인코더로 가중치를 로드합니다. 일부 "
"플러그인에는 다른 층에서 가중치를 로드할 수 있는 특정 구성 옵션이 있을 수 있"
"습니다. 가중치는 새 모델을 생성할 때만 로드됩니다. 기존 모델을 재개하는 경우 "
"이 옵션은 무시됩니다. 일반적으로 나머지 모델이 인코더를 따라잡는 동안에도 '가"
"중치 동결'이 필요합니다.\n"
"주의: 가중치는 훈련하려는 플러그인 모델에서만 로드할 수 있습니다."

#: lib/cli/args_train.py:99
msgid ""
"R|Select which trainer to use. Trainers can be configured from the Settings "
"menu or the config folder.\n"
"L|original: The original model created by /u/deepfakes.\n"
"L|dfaker: 64px in/128px out model from dfaker. Enable 'warp-to-landmarks' "
"for full dfaker method.\n"
"L|dfl-h128: 128px in/out model from deepfacelab\n"
"L|dfl-sae: Adaptable model from deepfacelab\n"
"L|dlight: A lightweight, high resolution DFaker variant.\n"
"L|iae: A model that uses intermediate layers to try to get better details\n"
"L|lightweight: A lightweight model for low-end cards. Don't expect great "
"results. Can train as low as 1.6GB with batch size 8.\n"
"L|realface: A high detail, dual density model based on DFaker, with "
"customizable in/out resolution. The autoencoders are unbalanced so B>A swaps "
"won't work so well. By andenixa et al. Very configurable.\n"
"L|unbalanced: 128px in/out model from andenixa. The autoencoders are "
"unbalanced so B>A swaps won't work so well. Very configurable.\n"
"L|villain: 128px in/out model from villainguy. Very resource hungry (You "
"will require a GPU with a fair amount of VRAM). Good for details, but more "
"susceptible to color differences."
msgstr ""
"R|사용할 훈련 모델을 선택합니다. 훈련 모델은 설정 메뉴 또는 구성 폴더에서 구"
"성할 수 있습니다.\n"
"L|original: /u/deepfakes로 만든 원래 모델입니다.\n"
"L|dfaker: 64px in/128px out 모델 from dfaker. Full dfaker 메서드에 대해 '특징"
"점으로 변환'를 활성화합니다.\n"
"L|dfl-h128: Deepfake lab의 128px in/out 모델\n"
"L|dfl-sae: Deepface Lab의 적응형 모델\n"
"L|dlight: 경량, 고해상도 DFaker 변형입니다.\n"
"L|iae: 중간 층들을 사용하여 더 나은 세부 정보를 얻기 위해 노력하는 모델.\n"
"L|lightweight: 저가형 카드용 경량 모델. 좋은 결과를 기대하지 마세요. 최대한 "
"낮게 잡아서 배치 사이즈 8에 1.6GB까지 훈련이 가능합니다.\n"
"L|realface: DFaker를 기반으로 한 높은 디테일의 이중 밀도 모델로, 사용자 정의 "
"가능한 입/출력 해상도를 제공합니다. 오토인코더가 불균형하여 B>A 스왑이 잘 작"
"동하지 않습니다. Andenixa 등에 의해. 매우 구성 가능합니다.\n"
"L|unbalanced: andenixa의 128px in/out 모델. 오토인코더가 불균형하여 B>A 스왑"
"이 잘 작동하지 않습니다. 매우 구성 가능합니다.\n"
"L|villain : villainguy의 128px in/out 모델. 리소스가 매우 부족합니다( 상당한 "
"양의 VRAM이 있는 GPU가 필요합니다). 세부 사항에는 좋지만 색상 차이에 더 취약"
"합니다."

#: lib/cli/args_train.py:125
msgid ""
"Output a summary of the model and exit. If a model folder is provided then a "
"summary of the saved model is displayed. Otherwise a summary of the model "
"that would be created by the chosen plugin and configuration settings is "
"displayed."
msgstr ""
"모델 요약을 출력하고 종료합니다. 모델 폴더가 제공되면 저장된 모델의 요약이 표"
"시됩니다. 그렇지 않으면 선택한 플러그인 및 구성 설정에 의해 생성되는 모델 요"
"약이 표시됩니다."

#: lib/cli/args_train.py:135
msgid ""
"Freeze the weights of the model. Freezing weights means that some of the "
"parameters in the model will no longer continue to learn, but those that are "
"not frozen will continue to learn. For most models, this will freeze the "
"encoder, but some models may have configuration options for freezing other "
"layers."
msgstr ""
"모델의 가중치를 동결합니다. 가중치를 고정하면 모델의 일부 매개변수가 더 이상 "
"학습되지 않지만 고정되지 않은 매개변수는 계속 학습됩니다. 대부분의 모델에서 "
"이렇게 하면 인코더가 고정되지만 일부 모델에는 다른 레이어를 고정하기 위한 구"
"성 옵션이 있을 수 있습니다."

#: lib/cli/args_train.py:147 lib/cli/args_train.py:160
#: lib/cli/args_train.py:175 lib/cli/args_train.py:191
#: lib/cli/args_train.py:200
msgid "training"
msgstr "훈련"

#: lib/cli/args_train.py:149
msgid ""
"Batch size. This is the number of images processed through the model for "
"each side per iteration. NB: As the model is fed 2 sides at a time, the "
"actual number of images within the model at any one time is double the "
"number that you set here. Larger batches require more GPU RAM."
msgstr ""
"배치 크기. 반복당 각 측면에 대해 모델을 통해 처리되는 이미지 수입니다. NB: "
"한 번에 모델에게 2개의 측면이 공급되므로 한 번에 모델 내의 실제 이미지 수는 "
"여기에서 설정한 수의 두 배입니다. 더 큰 배치에는 더 많은 GPU RAM이 필요합니"
"다."

#: lib/cli/args_train.py:162
msgid ""
"Length of training in iterations. This is only really used for automation. "
"There is no 'correct' number of iterations a model should be trained for. "
"You should stop training when you are happy with the previews. However, if "
"you want the model to stop automatically at a set number of iterations, you "
"can set that value here."
msgstr ""
"반복에서 훈련 길이. 이것은 실제로 자동화에만 사용됩니다. 모델을 훈련해야 하"
"는 '올바른' 반복 횟수는 없습니다. 미리 보기에 만족하면 훈련을 중단해야 합니"
"다. 그러나 설정된 반복 횟수에서 모델이 자동으로 중지되도록 하려면 여기에서 해"
"당 값을 설정할 수 있습니다."

#: lib/cli/args_train.py:177
msgid ""
"R|Select the distribution stategy to use.\n"
"L|default: Use Tensorflow's default distribution strategy.\n"
"L|central-storage: Centralizes variables on the CPU whilst operations are "
"performed on 1 or more local GPUs. This can help save some VRAM at the cost "
"of some speed by not storing variables on the GPU. Note: Mixed-Precision is "
"not supported on multi-GPU setups.\n"
"L|mirrored: Supports synchronous distributed training across multiple local "
"GPUs. A copy of the model and all variables are loaded onto each GPU with "
"batches distributed to each GPU at each iteration."
msgstr ""
"R|사용할 배포 상태를 선택합니다.\n"
"L|default: Tensorflow의 기본 배포 전략을 사용합니다.\n"
"L|central-storage: 작업이 1개 이상의 로컬 GPU에서 수행되는 동안 CPU의 변수를 "
"중앙 집중화합니다. 이렇게 하면 GPU에 변수를 저장하지 않음으로써 약간의 속도"
"를 희생하여 일부 VRAM을 절약할 수 있습니다. 참고: 다중 정밀도는 다중 GPU 설정"
"에서 지원되지 않습니다.\n"
"L|mirrored: 여러 로컬 GPU에서 동기화 분산 훈련을 지원합니다. 모델의 복사본과 "
"모든 변수는 각 반복에서 각 GPU에 배포된 배치들와 함께 각 GPU에 로드됩니다."

#: lib/cli/args_train.py:193
msgid ""
"Disables TensorBoard logging. NB: Disabling logs means that you will not be "
"able to use the graph or analysis for this session in the GUI."
msgstr ""
"텐서보드 로깅을 비활성화합니다. 주의: 로그를 비활성화하면 GUI에서 이 세션에 "
"대한 그래프 또는 분석을 사용할 수 없습니다."

#: lib/cli/args_train.py:202
msgid ""
"Use the Learning Rate Finder to discover the optimal learning rate for "
"training. For new models, this will calculate the optimal learning rate for "
"the model. For existing models this will use the optimal learning rate that "
"was discovered when initializing the model. Setting this option will ignore "
"the manually configured learning rate (configurable in train settings)."
msgstr ""
"학습률 찾기를 사용하여 훈련을 위한 최적의 학습률을 찾아보세요. 새 모델의 경"
"우 모델에 대한 최적의 학습률을 계산합니다. 기존 모델의 경우 모델을 초기화할 "
"때 발견된 최적의 학습률을 사용합니다. 이 옵션을 설정하면 수동으로 구성된 학습"
"률(기차 설정에서 구성 가능)이 무시됩니다."

#: lib/cli/args_train.py:215 lib/cli/args_train.py:225
msgid "Saving"
msgstr "저장"

#: lib/cli/args_train.py:216
msgid "Sets the number of iterations between each model save."
msgstr "각 모델 저장 사이의 반복 횟수를 설정합니다."

#: lib/cli/args_train.py:227
msgid ""
"Sets the number of iterations before saving a backup snapshot of the model "
"in it's current state. Set to 0 for off."
msgstr ""
"현재 상태에서 모델의 백업 스냅샷을 저장하기 전에 반복할 횟수를 설정합니다. 0"
"으로 설정하면 꺼집니다."

#: lib/cli/args_train.py:234 lib/cli/args_train.py:246
#: lib/cli/args_train.py:258
msgid "timelapse"
msgstr "타임랩스"

#: lib/cli/args_train.py:236
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. "
"This should be the input folder of 'A' faces that you would like to use for "
"creating the timelapse. You must also supply a --timelapse-output and a --"
"timelapse-input-B parameter."
msgstr ""
"타임랩스를 만드는 옵션입니다. Timelapse(시간 경과)는 저장을 반복할 때마다 선"
"택한 얼굴의 이미지를 Timelapse-output(시간 경과 출력) 폴더에 저장합니다. 타임"
"랩스를 만드는 데 사용할 'A' 얼굴의 입력 폴더여야 합니다. 또한 사용자는 --"
"timelapse-output 및 --timelapse-input-B 매개 변수를 제공해야 합니다."

#: lib/cli/args_train.py:248
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. "
"This should be the input folder of 'B' faces that you would like to use for "
"creating the timelapse. You must also supply a --timelapse-output and a --"
"timelapse-input-A parameter."
msgstr ""
"타임 랩스를 만드는 데 선택적입니다. Timelapse(시간 경과)는 저장을 반복할 때마"
"다 선택한 얼굴의 이미지를 Timelapse-output(시간 경과 출력) 폴더에 저장합니"
"다. 타임 랩스를 만드는 데 사용할 'B' 얼굴의 입력 폴더여야 합니다. 또한 사용자"
"는 --timelapse-output 및 --timelapse-input-A 매개 변수를 제공해야 합니다."

#: lib/cli/args_train.py:260
msgid ""
"Optional for creating a timelapse. Timelapse will save an image of your "
"selected faces into the timelapse-output folder at every save iteration. If "
"the input folders are supplied but no output folder, it will default to your "
"model folder/timelapse/"
msgstr ""
"타임랩스를 만드는 데 선택적입니다. Timelapse(시간 경과)는 저장을 반복할 때마"
"다 선택한 얼굴의 이미지를 Timelapse-output(시간 경과 출력) 폴더에 저장합니"
"다. 입력 폴더가 제공되었지만 출력 폴더가 없는 경우 모델 폴더에/timelapse/로 "
"기본 설정됩니다"

#: lib/cli/args_train.py:269 lib/cli/args_train.py:276
msgid "preview"
msgstr "미리보기"

#: lib/cli/args_train.py:270
msgid "Show training preview output. in a separate window."
msgstr "훈련 미리보기 결과를 각기 다른 창에서 보여줍니다."

#: lib/cli/args_train.py:278
msgid ""
"Writes the training result to a file. The image will be stored in the root "
"of your FaceSwap folder."
msgstr ""
"훈련 결과를 파일에 씁니다. 이미지는 Faceswap 폴더의 최상위 폴더에 저장됩니다."

#: lib/cli/args_train.py:285 lib/cli/args_train.py:295
#: lib/cli/args_train.py:305 lib/cli/args_train.py:315
msgid "augmentation"
msgstr "보정"

#: lib/cli/args_train.py:287
msgid ""
"Warps training faces to closely matched Landmarks from the opposite face-set "
"rather than randomly warping the face. This is the 'dfaker' way of doing "
"warping."
msgstr ""
"무작위로 얼굴을 변환하지 않고 반대쪽 얼굴 세트에서 특징점과 밀접하게 일치하도"
"록 훈련 얼굴을 변환해줍니다. 이것은 변환하는 'dfaker' 방식이다."

#: lib/cli/args_train.py:297
msgid ""
"To effectively learn, a random set of images are flipped horizontally. "
"Sometimes it is desirable for this not to occur. Generally this should be "
"left off except for during 'fit training'."
msgstr ""
"효과적으로 학습하기 위해 임의의 이미지 세트를 수평으로 뒤집습니다. 때때로 이"
"런 일이 일어나지 않는 것이 바람직합니다. 일반적으로 'fit training' 중을 제외"
"하고는 이 작업을 중단해야 합니다."

#: lib/cli/args_train.py:307
msgid ""
"Color augmentation helps make the model less susceptible to color "
"differences between the A and B sets, at an increased training time cost. "
"Enable this option to disable color augmentation."
msgstr ""
"색상 보정은 모델이 A와 B 세트 사이의 색상 차이에 덜 민감하게 만드는 데 도움"
"이 되며, 훈련 시간 비용이 증가합니다. 색상 보저를 사용하지 않으려면 이 옵션"
"을 사용합니다."

#: lib/cli/args_train.py:317
msgid ""
"Warping is integral to training the Neural Network. This option should only "
"be enabled towards the very end of training to try to bring out more detail. "
"Think of it as 'fine-tuning'. Enabling this option from the beginning is "
"likely to kill a model and lead to terrible results."
msgstr ""
"변환은 신경망을 훈련하는 데 필수적입니다. 이 옵션은 보다 세부적인 것들을 뽑아"
"내위하여 훈련 막바지까지 활성화하여야 합니다. 이것은 '미세 조정'이라고 생각하"
"면 됩니다. 처음부터 이 옵션을 활성화하면 모델이 죽을 수있고 끔찍한 결과를 초"
"래할 수 있습니다."
